#Do not change the way of queries, sparkProperties, sparkSqlProperties. Just change the values inside strings

#queries to be run
queries="q1,q2,q3,q4,q5,q6,q7,q8,q9,q10,q11,q12,q13,q14a,q14b,q15,q16,q17,q18,q19,q20,q21,q22,q23a,q23b,q24a,q24b,q25,q26,q27,q28,q29,q30,q31,q32,q33,q34,q35,q36,q37,q38,q39a,q39b,q40,q41,q42,q43,q44,q45,q46,q47,q48,q49,q50,q51,q52,q53,q54,q55,q56,q57,q58,q59,q60,q61,q62,q63,q64,q65,q66,q67,q68,q69,q70,q71,q72,q73,q74,q75,q76,q77,q78,q79,q80,q81,q82,q83,q84,q85,q86,q87,q88,q89,q90,q91,q92,q93,q94,q95,q96,q97,q98,q99"

#spark Properties spefied in lead
#spark-executor-cores has nothing to do with CPU cores available.
#sparkProperties="-J-Xmx2g -spark.network.timeout=300s -spark.driver.maxResultSize=2g -spark.shuffle.sort.bypassMergeThreshold=28"
# the lead uses heap, not off-heap memory. No need to specify -memory-size
sparkProperties="-heap-size=4g -spark.driver.maxResultSize=2g"

#Spark Sql properties are specified while executing query
#spark.sql.shuffle.partitions=${shufflePartitions},spark.sql.inMemoryColumnarStorage.compressed=${inMemoryColumnarStorageCompressed}
#spark.sql.inMemoryColumnarStorage.compressed=false
# enable cross join in sql props to allow running some queries that fail otherwise in Spark, SnappyData
sparkSqlProps="\"spark.sql.crossJoin.enabled=true\""

#location of checkout
SnappyData=$HOME/SNAPPY/CHECKOUT/snappydata/build-artifacts/scala-2.11/snappy
#SnappyData=$HOME/SNAPPY/CHECKOUT/snappydata-0.7-bin

buckets_ColumnTable=5

ResultCollection=false

WarmupRuns=1
AverageRuns=1

#Machine Setup
locator=$HOSTNAME
leads=$HOSTNAME
servers=($HOSTNAME)

#Log Directories
locatorDir=$HOME/SNAPPY/OUTPUT/TPCDS/locator
leadDir=$HOME/SNAPPY/OUTPUT/TPCDS/lead
serverDir=$HOME/SNAPPY/OUTPUT/TPCDS/server

#Locator Properties
# Some disgnostic options here for reference that do not need to be specified as defaults
#locatorProperties="-conserve-sockets=false -J-Xloggc:gc.log -J-XX:+PrintGCDetails -J-XX:+PrintGCDateStamps -J-XX:+PrintGCTimeStamps -J-XX:+PrintHeapAtGC"
locatorProperties=""

#Server properties
serverMemory="-heap-size=2g -memory-size=4g  -conserve-sockets=false-J-XX:NewRatio=9 -J-Xloggc:gc.log -J-XX:+PrintGCDetails -J-XX:+PrintGCDateStamps -J-XX:+PrintGCTimeStamps -J-XX:+PrintHeapAtGC"


# location of jar which has TPCH related class files
appJar=$HOME/SNAPPY/CHECKOUT/snappydata/cluster/build-artifacts/scala-2.11/libs/snappydata-cluster_2.11-1.1.1-tests.jar

#Size of the TPCH data. Do not chage format
#dataSize=1GB_Stages
#dataSize=1GB

#Location of the TPCH Data. Make sure directory name is same as the dataSize specified above
dataDir=$HOME/SNAPPY/DATA/TPCDS/data

#QueryPath
queryPath=$HOME/SNAPPY/CHECKOUT/snappydata/spark/sql/core/src/test/resources/tpcds

