dataTypes="\"csv-parquet\""
#dataTypes="\"parquet\""
#spark Properties spefied in lead
#spark-executor-cores has nothing to do with CPU cores available.
sparkProperties="-J-Xmx2g -spark.network.timeout=300s -spark.driver.maxResultSize=2g -spark.shuffle.sort.bypassMergeThreshold=28"

#Spark Sql properties are specified while executing query
#spark.sql.shuffle.partitions=${shufflePartitions},spark.sql.inMemoryColumnarStorage.compressed=${inMemoryColumnarStorageCompressed}
#spark.sql.inMemoryColumnarStorage.compressed=false
sparkSqlProperties="\"spark.sql.shuffle.partitions=31,spark.sql.crossJoin.enabled=true\""

#location of checkout
SnappyData=/home/kishor/snappy/snappydata/build-artifacts/scala-2.11/snappy

#number of buckets for order and lineitem tables
buckets_Order_Lineitem=3

#number of buckets for Customer, Part and PartSupplier tables
buckets_Cust_Part_PartSupp=3

#Are Nation, Region, Supplier tables column tables?
Nation_Region_Supp_col=false

#number of buckets for Nation, Region, Supplier
buckets_Nation_Region_Supp=3

#Machine Setup
locator=localhost
leads=localhost
servers=(localhost)

#Server Memmory to be used
serverMemory="-J-Xms5g"

# location of jar which has TPCH related class files
TPCHJar=/home/kishor/snappy/snappydata/cluster/build-artifacts/scala-2.11/libs/snappydata-cluster_2.11-1.3.1-tests.jar

#Size of the TPCH data. Do not chage format
#Location of the TPCH Data. Make sure directory name is same as the dataSize specified above
csvDataLocation=/home/kishor/snappy/TPCH_APP/TPCH_Data/1GB/lineitem.tbl

parquetDataLocation=~/snappy/snappydata/examples/quickstart/data/airlineParquetData

