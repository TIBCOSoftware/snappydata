apply plugin: 'scala'

compileScala.options.encoding = 'UTF-8'
// fix scala+java mix to all use compileScala which uses correct dependency order
sourceSets.main.scala.srcDir "src/main/java"
sourceSets.main.java.srcDirs = []

dependencies {
  compile 'org.scala-lang:scala-library:' + scalaVersion
  compile 'org.scala-lang:scala-reflect:' + scalaVersion
  if (new File(rootDir, "snappy-spark/build.gradle").exists()) {
    compile project(':snappy-spark:snappy-spark-core_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-sql_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-hive_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-streaming_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-mllib_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-streaming-kafka_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-streaming-twitter_' + scalaBinaryVersion)
  } else {
    compile('io.snappydata:snappy-spark-core_' + scalaBinaryVersion + ':' + sparkVersion) {
      exclude(group: 'org.apache.spark', module: 'spark-core')
    }
    compile('io.snappydata:snappy-spark-sql_' + scalaBinaryVersion + ':' + sparkVersion) {
      exclude(group: 'org.apache.spark', module: 'spark-core')
    }
    compile('io.snappydata:snappy-spark-hive_' + scalaBinaryVersion + ':' + sparkVersion) {
      exclude(group: 'org.apache.spark', module: 'spark-core')
    }
    compile('io.snappydata:snappy-spark-streaming_' + scalaBinaryVersion + ':' + sparkVersion) {
      exclude(group: 'org.apache.spark', module: 'spark-core')
    }
    compile('io.snappydata:snappy-spark-mllib_' + scalaBinaryVersion + ':' + sparkVersion) {
      exclude(group: 'org.apache.spark', module: 'spark-core')
    }
    compile('io.snappydata:snappy-spark-streaming-kafka_' + scalaBinaryVersion + ':' + sparkVersion) {
      exclude(group: 'org.apache.spark', module: 'spark-core')
    }
    compile('io.snappydata:snappy-spark-streaming-twitter_' + scalaBinaryVersion + ':' + sparkVersion) {
      exclude(group: 'org.apache.spark', module: 'spark-core')
    }
  }

  compile 'org.apache.tomcat:tomcat-jdbc:8.0.28'
  compile 'com.zaxxer:HikariCP-java6:2.3.12'

  testCompile 'org.scala-lang:scala-actors:' + scalaVersion
  testCompile 'org.scalatest:scalatest_' + scalaBinaryVersion + ':2.2.1'

  testRuntime 'org.pegdown:pegdown:1.1.0'
  if (new File(rootDir, "snappy-store/build.gradle").exists()) {
    testRuntime project(':snappy-store:gemfirexd:client')
  } else {
    testRuntime group: 'io.snappydata', name: 'gemfirexd-client', version: gemfireXDVersion
  }
}

task packageScalaDocs(type: Jar, dependsOn: scaladoc) {
  classifier = 'javadoc'
  from scaladoc
}
if (rootProject.hasProperty('enablePublish')) {
  artifacts {
    archives packageScalaDocs, packageSources
  }
}

testClasses.doLast {
  copyTestsCommonResources(buildDir)
}

scalaTest {
  maxParallelForks = 1
  maxHeapSize '4g'
  dependsOn ':cleanScalaTest'
  doFirst {
    // cleanup files since scalatest plugin does not honour workingDir yet
    cleanIntermediateFiles(project.path)
  }
  doLast {
    // cleanup files since scalatest plugin does not honour workingDir yet
    cleanIntermediateFiles(project.path)
  }
}
test {
  maxParallelForks = 4
  maxHeapSize '2g'
  dependsOn ':cleanJUnit'
}
