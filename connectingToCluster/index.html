<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="SnappyData Development Team">
  <link rel="shortcut icon" href="../favicon.ico">
  
  <title>Connecting using JDBC, Spark - SnappyData Documentation</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  <link href="../extra.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Connecting using JDBC, Spark";
    var mkdocs_page_input_path = "connectingToCluster.md";
    var mkdocs_page_url = "/connectingToCluster/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> SnappyData Documentation</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="..">Getting Started</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../build-instructions/">Building from source, project layout</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../snappyIntroduction/">Overview</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../features/">Key features</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../architecture/">Architecture</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../configuration/">Configuring the cluster</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 current">
        <a class="current" href="./">Connecting using JDBC, Spark</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#using-the-snappydata-sql-shell">Using the SnappyData SQL Shell</a></li>
                
            
                <li class="toctree-l3"><a href="#using-the-spark-shell-and-spark-submit">Using the Spark Shell and spark-submit</a></li>
                
            
                <li class="toctree-l3"><a href="#using-jdbc-with-snappydata">Using JDBC with SnappyData</a></li>
                
            
                <li class="toctree-l3"><a href="#accessing-snappydata-tables-from-spark-code">Accessing SnappyData Tables from Spark code</a></li>
                
            
            </ul>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../jobs/">Developing Apps using the Spark API</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../rowAndColumnTables/">Row and Column tables</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../aqp/">Synopsis Data Engine (SDE)</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../streamingWithSQL/">Stream processing using SQL</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../deployment/">Deployment topologies</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../apidocsintro/">API</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../aqp_aws/">Using iSight-Cloud</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>About</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../LICENSE/">License</a>
        
    </li>

        
    </ul>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">SnappyData Documentation</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Connecting using JDBC, Spark</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/SnappyDataInc/snappydata/edit/master/docs/connectingToCluster.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h2 id="using-the-snappydata-sql-shell">Using the SnappyData SQL Shell</h2>
<p>The SnappyData SQL Shell (<em>snappy-shell</em>) provides a simple command line interface to the SnappyData cluster. It allows you to run interactive queries on row and column stores, run administrative operations and run status commands on the cluster. Internally it uses JDBC to interact with the cluster. You can also use tools like SquirrelSQL or DBVisualizer( JDBC to connect to the cluster) to interact with SnappyData.</p>
<!--using javascript as the code language here... should this be sql?-->

<pre><code class="javascript">
// from the SnappyData base directory  
$ cd quickstart/scripts  
$ ../../bin/snappy-shell  
Version 2.0-BETA
snappy&gt; 

//Connect to the cluster as a client  
snappy&gt; connect client 'localhost:1527';

//Show active connections  
snappy&gt; show connections;

//Display cluster members by querying a system table  
snappy&gt; select id, kind, status, host, port from sys.members;
//or
snappy&gt; show members;

//Run a sql script. This particular script creates and loads a column table in the default schema  
snappy&gt; run 'create_and_load_column_table.sql';


//Run a sql script. This particular script creates and loads a row table in the default schema  
snappy&gt; run 'create_and_load_row_table.sql';
</code></pre>

<p>The complete list of commands available through <em>snappy_shell</em> can be found <a href="http://gemfirexd.docs.pivotal.io/docs-gemfirexd/reference/gfxd_commands/gfxd-launcher.html">here</a></p>
<h2 id="using-the-spark-shell-and-spark-submit">Using the Spark Shell and spark-submit</h2>
<p>SnappyData, out-of-the-box, collocates Spark executors and the SnappyData store for efficient data intensive computations. But it may be desirable to isolate the computational cluster for other reasons, for instance, a  computationally intensive Map-reduce machine learning algorithm that needs to iterate over a cached data set repeatedly. To support such scenarios it is also possible to run native Spark jobs that access a SnappyData cluster as a storage layer in a parallel fashion. To connect to the SnappyData store snappydata.store.locators property needs to be provided while starting the spark-shell. When spark-shell is started with this property it provides <a href="http://snappydatainc.github.io/snappydata/apidocs/#org.apache.spark.sql.SnappyContext">SnappyContext</a> as SQLContext and thus enabling the user to run all SnappyData functionalities.</p>
<pre><code class="bash">// from the SnappyData base directory  
# Start the spark shell in local mode. Pass SnappyData's locators host:port as a conf parameter.
# Change the UI port because the default port 4040 is being used by Snappyâ€™s lead. 
$ bin/spark-shell  --master local[*] --conf snappydata.store.locators=locatorhost:port --conf spark.ui.port=4041
scala&gt;
#Try few commands on the spark-shell. Following command shows the tables created using the snappy-shell
scala&gt; val airlineDF = sqlContext.table(&quot;airline&quot;).show
scala&gt; val resultset = sqlContext.sql(&quot;select * from airline&quot;)
</code></pre>

<p>Any spark application can also use the SnappyData as store and spark as computational engine by providing an extra snappydata.store.locators property in the conf.</p>
<pre><code class="bash"># Start the Spark standalone cluster from SnappyData base directory 
$ sbin/start-all.sh 
# Submit AirlineDataSparkApp to Spark Cluster with snappydata's locator host port.
$ bin/spark-submit --class io.snappydata.examples.AirlineDataSparkApp --master spark://masterhost:7077 --conf snappydata.store.locators=locatorhost:port --conf spark.ui.port=4041 $SNAPPY_HOME/examples/jars/quickstart-0.6.jar

# The results can be seen on the command line.
</code></pre>

<h2 id="using-jdbc-with-snappydata">Using JDBC with SnappyData</h2>
<p>SnappyData ships with a few JDBC drivers. 
The connection URL typically points to one of the Locators. Underneath the covers the driver acquires the endpoints for all the servers in the cluster along with load information and automatically connects clients to one of the data servers directly. The driver provides HA by automatically swizzling underlying physical connections in case servers were to fail. </p>
<pre><code class="java">
// 1527 is the default port a Locator or Server uses to listen for thin client connections
Connection c = DriverManager.getConnection (&quot;jdbc:snappydata://locatorHostName:1527/&quot;);
// While, clients typically just point to a locator, you could also directly point the 
//   connection at a server endpoint
</code></pre>

<h2 id="accessing-snappydata-tables-from-spark-code">Accessing SnappyData Tables from Spark code</h2>
<p>Spark applications access the SnappyStore using the new <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html#jdbc-to-other-databases">Spark Data Source API</a>. </p>
<p>By default, SnappyData servers runs the Spark Executors collocated with the data store. And, the default store provider is SnappyData. 
When the spark program connects to the cluster using a <a href="http://snappydatainc.github.io/snappydata/apidocs/#org.apache.spark.sql.SnappyContext">SnappyContext</a> (extends SQLContext), there is no need to configure the database URL and other options.  </p>
<pre><code class="scala">// Here is an Scala example 
  val sc = new org.apache.spark.SparkContext(conf)
  val snContext = org.apache.spark.sql.SnappyContext(sc)

  val props = Map[String, String]()
  // Save some application dataframe into a SnappyData row table
  myAppDataFrame.write.format(&quot;row&quot;).options(props).saveAsTable(&quot;MutableTable&quot;)

</code></pre>

<p>When running a native spark program, you can access SnappyData purely as a DataSource ...</p>
<pre><code class="scala">// Access SnappyData as a storage cluster .. 
  val sc = new org.apache.spark.SparkContext(conf)
  val sqlContext = new org.apache.spark.sql.SQLContext(sc)

  val props = Map(
    &quot;url&quot; -&gt; &quot;jdbc:snappydata://locatorHostName:1527/&quot;,
    &quot;poolImpl&quot; -&gt; &quot;tomcat&quot;, 
    &quot;user&quot; -&gt; &quot;app&quot;,
    &quot;password&quot; -&gt; &quot;app&quot;
    )

  // Save some application dataframe into a JDBC DataSource
  myAppDataFrame.write.format(&quot;jdbc&quot;).options(props).saveAsTable(&quot;MutableTable&quot;)
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../jobs/" class="btn btn-neutral float-right" title="Developing Apps using the Spark API">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../configuration/" class="btn btn-neutral" title="Configuring the cluster"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright &copy; 2016 SnappyData Inc.</p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/SnappyDataInc/snappydata" class="icon icon-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../configuration/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../jobs/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>

</body>
</html>
