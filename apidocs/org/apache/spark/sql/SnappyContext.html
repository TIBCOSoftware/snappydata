<!DOCTYPE html >
<html>
        <head>
          <title>SnappyContext - snappydata_2.11 1.1.1 API - org.apache.spark.sql.SnappyContext</title>
          <meta name="description" content="SnappyContext - snappydata 2.11 1.1.1 API - org.apache.spark.sql.SnappyContext" />
          <meta name="keywords" content="SnappyContext snappydata 2.11 1.1.1 API org.apache.spark.sql.SnappyContext" />
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      <link href="../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css" />
      <script type="text/javascript" src="../../../../lib/jquery.js" id="jquery-js"></script>
      <script type="text/javascript" src="../../../../lib/jquery-ui.js"></script>
      <script type="text/javascript" src="../../../../lib/template.js"></script>
      <script type="text/javascript" src="../../../../lib/tools.tooltip.js"></script>
      
      <script type="text/javascript">
         if(top === self) {
            var url = '../../../../index.html';
            var hash = 'org.apache.spark.sql.SnappyContext';
            var anchor = window.location.hash;
            var anchor_opt = '';
            if (anchor.length >= 1)
              anchor_opt = '@' + anchor.substring(1);
            window.location.href = url + '#' + hash + anchor_opt;
         }
   	  </script>
    
        </head>
        <body class="type">
      <div id="definition">
        <a href="SnappyContext$.html" title="See companion object"><img alt="Class/Object" src="../../../../lib/class_to_object_big.png" /></a>
        <p id="owner"><a href="../../../package.html" class="extype" name="org">org</a>.<a href="../../package.html" class="extype" name="org.apache">apache</a>.<a href="../package.html" class="extype" name="org.apache.spark">spark</a>.<a href="package.html" class="extype" name="org.apache.spark.sql">sql</a></p>
        <h1><a href="SnappyContext$.html" title="See companion object">SnappyContext</a></h1><h3><span class="morelinks"><div>
            Related Docs:
            <a href="SnappyContext$.html" title="See companion object">object SnappyContext</a>
            | <a href="package.html" class="extype" name="org.apache.spark.sql">package sql</a>
          </div></span></h3><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      </div>

      <h4 id="signature" class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <span class="name">SnappyContext</span><span class="result"> extends <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      </h4>
      
          <div id="comment" class="fullcommenttop"><div class="comment cmt"><p>Main entry point for SnappyData extensions to Spark. A SnappyContext
extends Spark's <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">org.apache.spark.sql.SQLContext</a> to work with Row and
Column tables. Any DataFrame can be managed as SnappyData tables and any
table can be accessed as a DataFrame. This integrates the SQLContext
functionality with the Snappy store.</p><p>When running in the <b>embedded </b> mode (i.e. Spark executor collocated
with Snappy data store), Applications typically submit Jobs to the
Snappy-JobServer
(provide link) and do not explicitly create a SnappyContext. A single
shared context managed by SnappyData makes it possible to re-use Executors
across client connections or applications.</p><p>SnappyContext uses a HiveMetaStore for catalog , which is
persistent. This enables table metadata info recreated on driver restart.</p><p>User should use obtain reference to a SnappyContext instance as below
val snc: SnappyContext = SnappyContext.getOrCreate(sparkContext)
</p></div><dl class="attributes block"> <dt>Self Type</dt><dd><a href="" class="extype" name="org.apache.spark.sql.SnappyContext">SnappyContext</a></dd><dt>To do</dt><dd><span class="cmt"><p>Provide links to above descriptions</p></span>, <span class="cmt"><p>document describing the Job server API</p></span></dd><dt>See also</dt><dd><span class="cmt"><p>https://github.com/SnappyDataInc/snappydata#interacting-with-snappydata</p></span><span class="cmt"><p>https://github.com/SnappyDataInc/snappydata#step-1---start-the-snappydata-cluster</p></span></dd></dl><div class="toggleContainer block">
          <span class="toggle">Linear Supertypes</span>
          <div class="superTypes hiddenContent"><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a>, <span class="extype" name="scala.Serializable">Serializable</span>, <span class="extype" name="java.io.Serializable">Serializable</span>, <span class="extype" name="org.apache.spark.internal.Logging">internal.Logging</span>, <a href="../../../../scala/package.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a>, <span class="extype" name="scala.Any">Any</span></div>
        </div></div>
        

      <div id="mbrsel">
        <div id="textfilter"><span class="pre"></span><span class="input"><input id="mbrsel-input" type="text" accesskey="/" /></span><span class="post"></span></div>
        <div id="order">
              <span class="filtertype">Ordering</span>
              <ol>
                
                <li class="alpha in"><span>Alphabetic</span></li>
                <li class="inherit out"><span>By Inheritance</span></li>
              </ol>
            </div>
        <div id="ancestors">
                <span class="filtertype">Inherited<br />
                </span>
                <ol id="linearization">
                  <li class="in" name="org.apache.spark.sql.SnappyContext"><span>SnappyContext</span></li><li class="in" name="org.apache.spark.sql.SQLContext"><span>SQLContext</span></li><li class="in" name="scala.Serializable"><span>Serializable</span></li><li class="in" name="java.io.Serializable"><span>Serializable</span></li><li class="in" name="org.apache.spark.internal.Logging"><span>Logging</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li>
                </ol>
              </div><div id="ancestors">
            <span class="filtertype"></span>
            <ol>
              <li class="hideall out"><span>Hide All</span></li>
              <li class="showall in"><span>Show All</span></li>
            </ol>
          </div>
        <div id="visbl">
            <span class="filtertype">Visibility</span>
            <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
          </div>
      </div>

      <div id="template">
        <div id="allMembers">
        <div id="constructors" class="members">
              <h3>Instance Constructors</h3>
              <ol><li name="org.apache.spark.sql.SnappyContext#&lt;init&gt;" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(sc:org.apache.spark.SparkContext):org.apache.spark.sql.SnappyContext"></a>
      <a id="&lt;init&gt;:SnappyContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">SnappyContext</span><span class="params">(<span name="sc">sc: <a href="../SparkContext.html" class="extype" name="org.apache.spark.SparkContext">SparkContext</a></span>)</span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@&lt;init&gt;(sc:org.apache.spark.SparkContext):org.apache.spark.sql.SnappyContext" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../package.html" class="extype" name="org.apache.spark">org.apache.spark</a>] </dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#&lt;init&gt;" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(snappySession:org.apache.spark.sql.SnappySession):org.apache.spark.sql.SnappyContext"></a>
      <a id="&lt;init&gt;:SnappyContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">SnappyContext</span><span class="params">(<span name="snappySession">snappySession: <a href="SnappySession.html" class="extype" name="org.apache.spark.sql.SnappySession">SnappySession</a></span>)</span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@&lt;init&gt;(snappySession:org.apache.spark.sql.SnappySession):org.apache.spark.sql.SnappyContext" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../package.html" class="extype" name="org.apache.spark">org.apache.spark</a>] </dd></dl></div>
    </li></ol>
            </div>

        

        

        <div id="values" class="values members">
              <h3>Value Members</h3>
              <ol><li name="scala.AnyRef#!=" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="!=(x$1:Any):Boolean"></a>
      <a id="!=(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $bang$eq" class="name">!=</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@!=(x$1:Any):Boolean" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef###" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="##():Int"></a>
      <a id="##():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $hash$hash" class="name">##</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@##():Int" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#==" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="==(x$1:Any):Boolean"></a>
      <a id="==(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $eq$eq" class="name">==</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@==(x$1:Any):Boolean" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#alterTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="alterTable(tableName:String,isAddColumn:Boolean,column:org.apache.spark.sql.types.StructField,extensions:String):Unit"></a>
      <a id="alterTable(String,Boolean,StructField,String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">alterTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="isAddColumn">isAddColumn: <span class="extype" name="scala.Boolean">Boolean</span></span>, <span name="column">column: <a href="types/StructField.html" class="extype" name="org.apache.spark.sql.types.StructField">StructField</a></span>, <span name="extensions">extensions: <span class="extype" name="scala.Predef.String">String</span> = <span class="symbol">&quot;&quot;</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@alterTable(tableName:String,isAddColumn:Boolean,column:org.apache.spark.sql.types.StructField,extensions:String):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">alter table adds/drops provided column, only supprted for row tables.</p><div class="fullcomment"><div class="comment cmt"><p>alter table adds/drops provided column, only supprted for row tables.
For adding a column isAddColumn should be true, else it will be drop column</p></div></div>
    </li><li name="org.apache.spark.sql.SnappyContext#appendToTempTableCache" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="appendToTempTableCache(df:org.apache.spark.sql.DataFrame,table:String,storageLevel:org.apache.spark.storage.StorageLevel):Unit"></a>
      <a id="appendToTempTableCache(DataFrame,String,StorageLevel):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">appendToTempTableCache</span><span class="params">(<span name="df">df: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>, <span name="table">table: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="storageLevel">storageLevel: <a href="../storage/StorageLevel.html" class="extype" name="org.apache.spark.storage.StorageLevel">StorageLevel</a> = <span class="symbol"><span class="name"><a href="../../../package.html">StorageLevel.MEMORY_AND_DISK</a></span></span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@appendToTempTableCache(df:org.apache.spark.sql.DataFrame,table:String,storageLevel:org.apache.spark.storage.StorageLevel):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Append dataframe to cache table in Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Append dataframe to cache table in Spark.
</p></div><dl class="paramcmts block"><dt class="param">storageLevel</dt><dd class="cmt"><p>default storage level is MEMORY_AND_DISK</p></dd><dt>returns</dt><dd class="cmt"><p>@todo -&gt; return type?</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/DeveloperApi.html" class="extype" name="org.apache.spark.annotation.DeveloperApi">DeveloperApi</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="scala.Any#asInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="asInstanceOf[T0]:T0"></a>
      <a id="asInstanceOf[T0]:T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Any.asInstanceOf.T0">T0</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@asInstanceOf[T0]:T0" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#baseRelationToDataFrame" visbl="pub" data-isabs="false" fullComment="yes" group="dataframes">
      <a id="baseRelationToDataFrame(baseRelation:org.apache.spark.sql.sources.BaseRelation):org.apache.spark.sql.DataFrame"></a>
      <a id="baseRelationToDataFrame(BaseRelation):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">baseRelationToDataFrame</span><span class="params">(<span name="baseRelation">baseRelation: <a href="sources/BaseRelation.html" class="extype" name="org.apache.spark.sql.sources.BaseRelation">BaseRelation</a></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@baseRelationToDataFrame(baseRelation:org.apache.spark.sql.sources.BaseRelation):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Convert a <span class="extype" name="BaseRelation">BaseRelation</span> created for external data sources into a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Convert a <span class="extype" name="BaseRelation">BaseRelation</span> created for external data sources into a <code>DataFrame</code>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#cacheTable" visbl="pub" data-isabs="false" fullComment="yes" group="cachemgmt">
      <a id="cacheTable(tableName:String):Unit"></a>
      <a id="cacheTable(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cacheTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@cacheTable(tableName:String):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Caches the specified table in-memory.</p><div class="fullcomment"><div class="comment cmt"><p>Caches the specified table in-memory.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#clear" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="clear():Unit"></a>
      <a id="clear():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clear</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@clear():Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      
    </li><li name="org.apache.spark.sql.SQLContext#clearCache" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="clearCache():Unit"></a>
      <a id="clearCache():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clearCache</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@clearCache():Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Removes all cached tables from the in-memory cache.</p><div class="fullcomment"><div class="comment cmt"><p>Removes all cached tables from the in-memory cache.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="scala.AnyRef#clone" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="clone():Object"></a>
      <a id="clone():AnyRef"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: <a href="../../../../scala/package.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@clone():Object" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.CloneNotSupportedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createApproxTSTopK" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createApproxTSTopK(topKName:String,baseTable:String,keyColumnName:String,topkOptions:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createApproxTSTopK(String,String,String,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createApproxTSTopK</span><span class="params">(<span name="topKName">topKName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="baseTable">baseTable: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="keyColumnName">keyColumnName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="topkOptions">topkOptions: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createApproxTSTopK(topKName:String,baseTable:String,keyColumnName:String,topkOptions:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Create approximate structure to query top-K with time series support.</p><div class="fullcomment"><div class="comment cmt"><p>Create approximate structure to query top-K with time series support. Java
friendly api.</p></div><dl class="paramcmts block"><dt class="param">topKName</dt><dd class="cmt"><p>the qualified name of the top-K structure</p></dd><dt class="param">baseTable</dt><dd class="cmt"><p>the base table of the top-K structure, if any, or null</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd></dl><dl class="attributes block"> <dt>To do</dt><dd><span class="cmt"><p>provide lot more details and examples to explain creating and
      using TopK with time series</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createApproxTSTopK" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createApproxTSTopK(topKName:String,baseTable:Option[String],keyColumnName:String,topkOptions:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createApproxTSTopK(String,Option[String],String,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createApproxTSTopK</span><span class="params">(<span name="topKName">topKName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="baseTable">baseTable: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="keyColumnName">keyColumnName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="topkOptions">topkOptions: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createApproxTSTopK(topKName:String,baseTable:Option[String],keyColumnName:String,topkOptions:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Create approximate structure to query top-K with time series support.</p><div class="fullcomment"><div class="comment cmt"><p>Create approximate structure to query top-K with time series support.</p></div><dl class="paramcmts block"><dt class="param">topKName</dt><dd class="cmt"><p>the qualified name of the top-K structure</p></dd><dt class="param">baseTable</dt><dd class="cmt"><p>the base table of the top-K structure, if any</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd></dl><dl class="attributes block"> <dt>To do</dt><dd><span class="cmt"><p>provide lot more details and examples to explain creating and
      using TopK with time series</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createApproxTSTopK" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createApproxTSTopK(topKName:String,baseTable:String,keyColumnName:String,inputDataSchema:org.apache.spark.sql.types.StructType,topkOptions:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createApproxTSTopK(String,String,String,StructType,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createApproxTSTopK</span><span class="params">(<span name="topKName">topKName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="baseTable">baseTable: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="keyColumnName">keyColumnName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="inputDataSchema">inputDataSchema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>, <span name="topkOptions">topkOptions: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createApproxTSTopK(topKName:String,baseTable:String,keyColumnName:String,inputDataSchema:org.apache.spark.sql.types.StructType,topkOptions:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Create approximate structure to query top-K with time series support.</p><div class="fullcomment"><div class="comment cmt"><p>Create approximate structure to query top-K with time series support.
Java friendly api.</p></div><dl class="paramcmts block"><dt class="param">topKName</dt><dd class="cmt"><p>the qualified name of the top-K structure</p></dd><dt class="param">baseTable</dt><dd class="cmt"><p>the base table of the top-K structure, if any, or null</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd></dl><dl class="attributes block"> <dt>To do</dt><dd><span class="cmt"><p>provide lot more details and examples to explain creating and
      using TopK with time series</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createApproxTSTopK" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createApproxTSTopK(topKName:String,baseTable:Option[String],keyColumnName:String,inputDataSchema:org.apache.spark.sql.types.StructType,topkOptions:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createApproxTSTopK(String,Option[String],String,StructType,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createApproxTSTopK</span><span class="params">(<span name="topKName">topKName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="baseTable">baseTable: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="keyColumnName">keyColumnName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="inputDataSchema">inputDataSchema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>, <span name="topkOptions">topkOptions: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createApproxTSTopK(topKName:String,baseTable:Option[String],keyColumnName:String,inputDataSchema:org.apache.spark.sql.types.StructType,topkOptions:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Create approximate structure to query top-K with time series support.</p><div class="fullcomment"><div class="comment cmt"><p>Create approximate structure to query top-K with time series support.</p></div><dl class="paramcmts block"><dt class="param">topKName</dt><dd class="cmt"><p>the qualified name of the top-K structure</p></dd><dt class="param">baseTable</dt><dd class="cmt"><p>the base table of the top-K structure, if any</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd></dl><dl class="attributes block"> <dt>To do</dt><dd><span class="cmt"><p>provide lot more details and examples to explain creating and
      using TopK with time series</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createDataFrame" visbl="pub" data-isabs="false" fullComment="yes" group="dataframes">
      <a id="createDataFrame(data:java.util.List[_],beanClass:Class[_]):org.apache.spark.sql.DataFrame"></a>
      <a id="createDataFrame(List[_],Class[_]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataFrame</span><span class="params">(<span name="data">data: <span class="extype" name="java.util.List">List</span>[_]</span>, <span name="beanClass">beanClass: <span class="extype" name="scala.Predef.Class">Class</span>[_]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataFrame(data:java.util.List[_],beanClass:Class[_]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Applies a schema to a List of Java Beans.</p><div class="fullcomment"><div class="comment cmt"><p>Applies a schema to a List of Java Beans.</p><p>WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
         SELECT * queries will return the columns in an undefined order.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createDataFrame" visbl="pub" data-isabs="false" fullComment="yes" group="dataframes">
      <a id="createDataFrame(rdd:org.apache.spark.api.java.JavaRDD[_],beanClass:Class[_]):org.apache.spark.sql.DataFrame"></a>
      <a id="createDataFrame(JavaRDD[_],Class[_]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataFrame</span><span class="params">(<span name="rdd">rdd: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[_]</span>, <span name="beanClass">beanClass: <span class="extype" name="scala.Predef.Class">Class</span>[_]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataFrame(rdd:org.apache.spark.api.java.JavaRDD[_],beanClass:Class[_]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Applies a schema to an RDD of Java Beans.</p><div class="fullcomment"><div class="comment cmt"><p>Applies a schema to an RDD of Java Beans.</p><p>WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
         SELECT * queries will return the columns in an undefined order.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createDataFrame" visbl="pub" data-isabs="false" fullComment="yes" group="dataframes">
      <a id="createDataFrame(rdd:org.apache.spark.rdd.RDD[_],beanClass:Class[_]):org.apache.spark.sql.DataFrame"></a>
      <a id="createDataFrame(RDD[_],Class[_]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataFrame</span><span class="params">(<span name="rdd">rdd: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[_]</span>, <span name="beanClass">beanClass: <span class="extype" name="scala.Predef.Class">Class</span>[_]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataFrame(rdd:org.apache.spark.rdd.RDD[_],beanClass:Class[_]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Applies a schema to an RDD of Java Beans.</p><div class="fullcomment"><div class="comment cmt"><p>Applies a schema to an RDD of Java Beans.</p><p>WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
         SELECT * queries will return the columns in an undefined order.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createDataFrame" visbl="pub" data-isabs="false" fullComment="yes" group="dataframes">
      <a id="createDataFrame(rows:java.util.List[org.apache.spark.sql.Row],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame"></a>
      <a id="createDataFrame(List[Row],StructType):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataFrame</span><span class="params">(<span name="rows">rows: <span class="extype" name="java.util.List">List</span>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataFrame(rows:java.util.List[org.apache.spark.sql.Row],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: DeveloperApi ::
Creates a <code>DataFrame</code> from a <span class="extype" name="java.util.List">java.util.List</span> containing <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s using the given schema.</p><div class="fullcomment"><div class="comment cmt"><p>:: DeveloperApi ::
Creates a <code>DataFrame</code> from a <span class="extype" name="java.util.List">java.util.List</span> containing <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s using the given schema.
It is important to make sure that the structure of every <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a> of the provided List matches
the provided schema. Otherwise, there will be runtime exception.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/DeveloperApi.html" class="extype" name="org.apache.spark.annotation.DeveloperApi">DeveloperApi</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createDataFrame" visbl="pub" data-isabs="false" fullComment="yes" group="dataframes">
      <a id="createDataFrame(rowRDD:org.apache.spark.api.java.JavaRDD[org.apache.spark.sql.Row],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame"></a>
      <a id="createDataFrame(JavaRDD[Row],StructType):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataFrame</span><span class="params">(<span name="rowRDD">rowRDD: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataFrame(rowRDD:org.apache.spark.api.java.JavaRDD[org.apache.spark.sql.Row],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: DeveloperApi ::
Creates a <code>DataFrame</code> from a <span class="extype" name="JavaRDD">JavaRDD</span> containing <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s using the given schema.</p><div class="fullcomment"><div class="comment cmt"><p>:: DeveloperApi ::
Creates a <code>DataFrame</code> from a <span class="extype" name="JavaRDD">JavaRDD</span> containing <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s using the given schema.
It is important to make sure that the structure of every <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a> of the provided RDD matches
the provided schema. Otherwise, there will be runtime exception.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/DeveloperApi.html" class="extype" name="org.apache.spark.annotation.DeveloperApi">DeveloperApi</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createDataFrame" visbl="pub" data-isabs="false" fullComment="yes" group="dataframes">
      <a id="createDataFrame(rowRDD:org.apache.spark.rdd.RDD[org.apache.spark.sql.Row],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame"></a>
      <a id="createDataFrame(RDD[Row],StructType):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataFrame</span><span class="params">(<span name="rowRDD">rowRDD: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataFrame(rowRDD:org.apache.spark.rdd.RDD[org.apache.spark.sql.Row],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: DeveloperApi ::
Creates a <code>DataFrame</code> from an <span class="extype" name="RDD">RDD</span> containing <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s using the given schema.</p><div class="fullcomment"><div class="comment cmt"><p>:: DeveloperApi ::
Creates a <code>DataFrame</code> from an <span class="extype" name="RDD">RDD</span> containing <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>s using the given schema.
It is important to make sure that the structure of every <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a> of the provided RDD matches
the provided schema. Otherwise, there will be runtime exception.
Example:</p><pre><span class="kw">import</span> org.apache.spark.sql._
<span class="kw">import</span> org.apache.spark.sql.types._
<span class="kw">val</span> sqlContext = <span class="kw">new</span> org.apache.spark.sql.SQLContext(sc)

<span class="kw">val</span> schema =
  StructType(
    StructField(<span class="lit">"name"</span>, StringType, <span class="kw">false</span>) ::
    StructField(<span class="lit">"age"</span>, IntegerType, <span class="kw">true</span>) :: Nil)

<span class="kw">val</span> people =
  sc.textFile(<span class="lit">"examples/src/main/resources/people.txt"</span>).map(
    _.split(<span class="lit">","</span>)).map(p <span class="kw">=&gt;</span> Row(p(<span class="num">0</span>), p(<span class="num">1</span>).trim.toInt))
<span class="kw">val</span> dataFrame = sqlContext.createDataFrame(people, schema)
dataFrame.printSchema
<span class="cmt">// root</span>
<span class="cmt">// |-- name: string (nullable = false)</span>
<span class="cmt">// |-- age: integer (nullable = true)</span>

dataFrame.createOrReplaceTempView(<span class="lit">"people"</span>)
sqlContext.sql(<span class="lit">"select name from people"</span>).collect.foreach(println)</pre></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/DeveloperApi.html" class="extype" name="org.apache.spark.annotation.DeveloperApi">DeveloperApi</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createDataFrame" visbl="pub" data-isabs="false" fullComment="yes" group="dataframes">
      <a id="createDataFrame[A&lt;:Product](data:Seq[A])(implicitevidence$2:reflect.runtime.universe.TypeTag[A]):org.apache.spark.sql.DataFrame"></a>
      <a id="createDataFrame[A&lt;:Product](Seq[A])(scala.reflect.api.JavaUniverse.TypeTag[A]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataFrame</span><span class="tparams">[<span name="A">A &lt;: <span class="extype" name="scala.Product">Product</span></span>]</span><span class="params">(<span name="data">data: <a href="../../../../scala/package.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataFrame.A">A</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.api.TypeTags.TypeTag">scala.reflect.api.JavaUniverse.TypeTag</span>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataFrame.A">A</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataFrame[A&lt;:Product](data:Seq[A])(implicitevidence$2:reflect.runtime.universe.TypeTag[A]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
Creates a DataFrame from a local Seq of Product.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a DataFrame from a local Seq of Product.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createDataFrame" visbl="pub" data-isabs="false" fullComment="yes" group="dataframes">
      <a id="createDataFrame[A&lt;:Product](rdd:org.apache.spark.rdd.RDD[A])(implicitevidence$1:reflect.runtime.universe.TypeTag[A]):org.apache.spark.sql.DataFrame"></a>
      <a id="createDataFrame[A&lt;:Product](RDD[A])(scala.reflect.api.JavaUniverse.TypeTag[A]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataFrame</span><span class="tparams">[<span name="A">A &lt;: <span class="extype" name="scala.Product">Product</span></span>]</span><span class="params">(<span name="rdd">rdd: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataFrame.A">A</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.api.TypeTags.TypeTag">scala.reflect.api.JavaUniverse.TypeTag</span>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataFrame.A">A</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataFrame[A&lt;:Product](rdd:org.apache.spark.rdd.RDD[A])(implicitevidence$1:reflect.runtime.universe.TypeTag[A]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
Creates a DataFrame from an RDD of Product (e.g.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a DataFrame from an RDD of Product (e.g. case classes, tuples).
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createDataFrameUsingRDD" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createDataFrameUsingRDD[A&lt;:Product](rdd:org.apache.spark.rdd.RDD[A])(implicitevidence$1:reflect.runtime.universe.TypeTag[A]):org.apache.spark.sql.DataFrame"></a>
      <a id="createDataFrameUsingRDD[A&lt;:Product](RDD[A])(scala.reflect.api.JavaUniverse.TypeTag[A]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataFrameUsingRDD</span><span class="tparams">[<span name="A">A &lt;: <span class="extype" name="scala.Product">Product</span></span>]</span><span class="params">(<span name="rdd">rdd: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="org.apache.spark.sql.SnappyContext.createDataFrameUsingRDD.A">A</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.api.TypeTags.TypeTag">scala.reflect.api.JavaUniverse.TypeTag</span>[<span class="extype" name="org.apache.spark.sql.SnappyContext.createDataFrameUsingRDD.A">A</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataFrameUsingRDD[A&lt;:Product](rdd:org.apache.spark.rdd.RDD[A])(implicitevidence$1:reflect.runtime.universe.TypeTag[A]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
Creates a <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a> from an RDD of Product (e.g.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a> from an RDD of Product (e.g. case classes, tuples).
This method handles generic array datatype like Array[Decimal]
</p></div></div>
    </li><li name="org.apache.spark.sql.SQLContext#createDataset" visbl="pub" data-isabs="false" fullComment="yes" group="dataset">
      <a id="createDataset[T](data:java.util.List[T])(implicitevidence$5:org.apache.spark.sql.Encoder[T]):org.apache.spark.sql.Dataset[T]"></a>
      <a id="createDataset[T](List[T])(Encoder[T]):Dataset[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataset</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="data">data: <span class="extype" name="java.util.List">List</span>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataset.T">T</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <a href="Encoder.html" class="extype" name="org.apache.spark.sql.Encoder">Encoder</a>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataset.T">T</span>]</span>)</span><span class="result">: <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataset.T">T</span>]</span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataset[T](data:java.util.List[T])(implicitevidence$5:org.apache.spark.sql.Encoder[T]):org.apache.spark.sql.Dataset[T]" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
Creates a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> from a <span class="extype" name="java.util.List">java.util.List</span> of a given type.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> from a <span class="extype" name="java.util.List">java.util.List</span> of a given type. This method requires an
encoder (to convert a JVM object of type <code>T</code> to and from the internal Spark SQL representation)
that is generally created automatically through implicits from a <code>SparkSession</code>, or can be
created explicitly by calling static methods on <a href="Encoders$.html" class="extype" name="org.apache.spark.sql.Encoders">Encoders</a>.</p><h4> Java Example </h4><pre><span class="std">List</span>&lt;<span class="std">String</span>&gt; data = Arrays.asList(<span class="lit">"hello"</span>, <span class="lit">"world"</span>);
Dataset&lt;<span class="std">String</span>&gt; ds = spark.createDataset(data, Encoders.STRING());</pre></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createDataset" visbl="pub" data-isabs="false" fullComment="yes" group="dataset">
      <a id="createDataset[T](data:org.apache.spark.rdd.RDD[T])(implicitevidence$4:org.apache.spark.sql.Encoder[T]):org.apache.spark.sql.Dataset[T]"></a>
      <a id="createDataset[T](RDD[T])(Encoder[T]):Dataset[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataset</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="data">data: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataset.T">T</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <a href="Encoder.html" class="extype" name="org.apache.spark.sql.Encoder">Encoder</a>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataset.T">T</span>]</span>)</span><span class="result">: <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataset.T">T</span>]</span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataset[T](data:org.apache.spark.rdd.RDD[T])(implicitevidence$4:org.apache.spark.sql.Encoder[T]):org.apache.spark.sql.Dataset[T]" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
Creates a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> from an RDD of a given type.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> from an RDD of a given type. This method requires an
encoder (to convert a JVM object of type <code>T</code> to and from the internal Spark SQL representation)
that is generally created automatically through implicits from a <code>SparkSession</code>, or can be
created explicitly by calling static methods on <a href="Encoders$.html" class="extype" name="org.apache.spark.sql.Encoders">Encoders</a>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createDataset" visbl="pub" data-isabs="false" fullComment="yes" group="dataset">
      <a id="createDataset[T](data:Seq[T])(implicitevidence$3:org.apache.spark.sql.Encoder[T]):org.apache.spark.sql.Dataset[T]"></a>
      <a id="createDataset[T](Seq[T])(Encoder[T]):Dataset[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createDataset</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="data">data: <a href="../../../../scala/package.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataset.T">T</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <a href="Encoder.html" class="extype" name="org.apache.spark.sql.Encoder">Encoder</a>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataset.T">T</span>]</span>)</span><span class="result">: <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>[<span class="extype" name="org.apache.spark.sql.SQLContext.createDataset.T">T</span>]</span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createDataset[T](data:Seq[T])(implicitevidence$3:org.apache.spark.sql.Encoder[T]):org.apache.spark.sql.Dataset[T]" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
Creates a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> from a local Seq of data of a given type.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> from a local Seq of data of a given type. This method requires an
encoder (to convert a JVM object of type <code>T</code> to and from the internal Spark SQL representation)
that is generally created automatically through implicits from a <code>SparkSession</code>, or can be
created explicitly by calling static methods on <a href="Encoders$.html" class="extype" name="org.apache.spark.sql.Encoders">Encoders</a>.</p><h4> Example </h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">case</span> <span class="kw">class</span> Person(name: <span class="std">String</span>, age: <span class="std">Long</span>)
<span class="kw">val</span> data = <span class="std">Seq</span>(Person(<span class="lit">"Michael"</span>, <span class="num">29</span>), Person(<span class="lit">"Andy"</span>, <span class="num">30</span>), Person(<span class="lit">"Justin"</span>, <span class="num">19</span>))
<span class="kw">val</span> ds = spark.createDataset(data)

ds.show()
<span class="cmt">// +-------+---+</span>
<span class="cmt">// |   name|age|</span>
<span class="cmt">// +-------+---+</span>
<span class="cmt">// |Michael| 29|</span>
<span class="cmt">// |   Andy| 30|</span>
<span class="cmt">// | Justin| 19|</span>
<span class="cmt">// +-------+---+</span></pre></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createExternalTable" visbl="pub" data-isabs="false" fullComment="yes" group="ddl_ops">
      <a id="createExternalTable(tableName:String,source:String,schema:org.apache.spark.sql.types.StructType,options:Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="createExternalTable(String,String,StructType,Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createExternalTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createExternalTable(tableName:String,source:String,schema:org.apache.spark.sql.types.StructType,options:Map[String,String]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">(Scala-specific)
Create an external table from the given path based on a data source, a schema and
a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific)
Create an external table from the given path based on a data source, a schema and
a set of options. Then, returns the corresponding DataFrame.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createExternalTable" visbl="pub" data-isabs="false" fullComment="yes" group="ddl_ops">
      <a id="createExternalTable(tableName:String,source:String,schema:org.apache.spark.sql.types.StructType,options:java.util.Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="createExternalTable(String,String,StructType,Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createExternalTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createExternalTable(tableName:String,source:String,schema:org.apache.spark.sql.types.StructType,options:java.util.Map[String,String]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Create an external table from the given path based on a data source, a schema and
a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>Create an external table from the given path based on a data source, a schema and
a set of options. Then, returns the corresponding DataFrame.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createExternalTable" visbl="pub" data-isabs="false" fullComment="yes" group="ddl_ops">
      <a id="createExternalTable(tableName:String,source:String,options:Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="createExternalTable(String,String,Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createExternalTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createExternalTable(tableName:String,source:String,options:Map[String,String]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">(Scala-specific)
Creates an external table from the given path based on a data source and a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific)
Creates an external table from the given path based on a data source and a set of options.
Then, returns the corresponding DataFrame.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createExternalTable" visbl="pub" data-isabs="false" fullComment="yes" group="ddl_ops">
      <a id="createExternalTable(tableName:String,source:String,options:java.util.Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="createExternalTable(String,String,Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createExternalTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createExternalTable(tableName:String,source:String,options:java.util.Map[String,String]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Creates an external table from the given path based on a data source and a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>Creates an external table from the given path based on a data source and a set of options.
Then, returns the corresponding DataFrame.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createExternalTable" visbl="pub" data-isabs="false" fullComment="yes" group="ddl_ops">
      <a id="createExternalTable(tableName:String,path:String,source:String):org.apache.spark.sql.DataFrame"></a>
      <a id="createExternalTable(String,String,String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createExternalTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createExternalTable(tableName:String,path:String,source:String):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Creates an external table from the given path based on a data source
and returns the corresponding DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Creates an external table from the given path based on a data source
and returns the corresponding DataFrame.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#createExternalTable" visbl="pub" data-isabs="false" fullComment="yes" group="ddl_ops">
      <a id="createExternalTable(tableName:String,path:String):org.apache.spark.sql.DataFrame"></a>
      <a id="createExternalTable(String,String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createExternalTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createExternalTable(tableName:String,path:String):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Creates an external table from the given path and returns the corresponding DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Creates an external table from the given path and returns the corresponding DataFrame.
It will use the default data source configured by spark.sql.sources.default.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createIndex" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createIndex(indexName:String,baseTable:String,indexColumns:Seq[(String,Option[org.apache.spark.sql.catalyst.expressions.SortDirection])],options:Map[String,String]):Unit"></a>
      <a id="createIndex(String,String,Seq[(String,Option[SortDirection])],Map[String,String]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createIndex</span><span class="params">(<span name="indexName">indexName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="baseTable">baseTable: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="indexColumns">indexColumns: <a href="../../../../scala/package.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[(<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Option">Option</span>[<a href="catalyst/expressions/SortDirection.html" class="extype" name="org.apache.spark.sql.catalyst.expressions.SortDirection">SortDirection</a>])]</span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createIndex(indexName:String,baseTable:String,indexColumns:Seq[(String,Option[org.apache.spark.sql.catalyst.expressions.SortDirection])],options:Map[String,String]):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Create an index on a table.</p><div class="fullcomment"><div class="comment cmt"><p>Create an index on a table.</p></div><dl class="paramcmts block"><dt class="param">indexName</dt><dd class="cmt"><p>Index name which goes in the catalog</p></dd><dt class="param">baseTable</dt><dd class="cmt"><p>Fully qualified name of table on which the index is created.</p></dd><dt class="param">indexColumns</dt><dd class="cmt"><p>Columns on which the index has to be created with the
                    direction of sorting. Direction can be specified as None.</p></dd><dt class="param">options</dt><dd class="cmt"><p>Options for indexes. For e.g.
               column table index - (&quot;COLOCATE_WITH&quot;-&gt;&quot;CUSTOMER&quot;).
               row table index - (&quot;INDEX_TYPE&quot;-&gt;&quot;GLOBAL HASH&quot;) or (&quot;INDEX_TYPE&quot;-&gt;&quot;UNIQUE&quot;)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createIndex" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createIndex(indexName:String,baseTable:String,indexColumns:java.util.List[String],sortOrders:java.util.List[Boolean],options:java.util.Map[String,String]):Unit"></a>
      <a id="createIndex(String,String,List[String],List[Boolean],Map[String,String]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createIndex</span><span class="params">(<span name="indexName">indexName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="baseTable">baseTable: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="indexColumns">indexColumns: <span class="extype" name="java.util.List">List</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="sortOrders">sortOrders: <span class="extype" name="java.util.List">List</span>[<span class="extype" name="java.lang.Boolean">Boolean</span>]</span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createIndex(indexName:String,baseTable:String,indexColumns:java.util.List[String],sortOrders:java.util.List[Boolean],options:java.util.Map[String,String]):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Create an index on a table.</p><div class="fullcomment"><div class="comment cmt"><p>Create an index on a table.</p></div><dl class="paramcmts block"><dt class="param">indexName</dt><dd class="cmt"><p>Index name which goes in the catalog</p></dd><dt class="param">baseTable</dt><dd class="cmt"><p>Fully qualified name of table on which the index is created.</p></dd><dt class="param">indexColumns</dt><dd class="cmt"><p>Columns on which the index has to be created along with the
                    sorting direction.</p></dd><dt class="param">sortOrders</dt><dd class="cmt"><p>Sorting direction for indexColumns. The direction of index will be
                    ascending if value is true and descending when value is false.
                    The values in this list must exactly match indexColumns list.
                    Direction can be specified as null in which case ascending is used.</p></dd><dt class="param">options</dt><dd class="cmt"><p>Options for indexes. For e.g.
               column table index - (&quot;COLOCATE_WITH&quot;-&gt;&quot;CUSTOMER&quot;).
               row table index - (&quot;INDEX_TYPE&quot;-&gt;&quot;GLOBAL HASH&quot;) or (&quot;INDEX_TYPE&quot;-&gt;&quot;UNIQUE&quot;)</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createSampleTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createSampleTable(tableName:String,baseTable:String,schema:org.apache.spark.sql.types.StructType,samplingOptions:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createSampleTable(String,String,StructType,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createSampleTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="baseTable">baseTable: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>, <span name="samplingOptions">samplingOptions: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createSampleTable(tableName:String,baseTable:String,schema:org.apache.spark.sql.types.StructType,samplingOptions:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Create a stratified sample table.</p><div class="fullcomment"><div class="comment cmt"><p>Create a stratified sample table. Java friendly version.</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>the qualified name of the table</p></dd><dt class="param">baseTable</dt><dd class="cmt"><p>the base table of the sample table, if any, or null</p></dd><dt class="param">schema</dt><dd class="cmt"><p>schema of the table</p></dd><dt class="param">samplingOptions</dt><dd class="cmt"><p>sampling options like QCS, reservoir size etc.</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd></dl><dl class="attributes block"> <dt>To do</dt><dd><span class="cmt"><p>provide lot more details and examples to explain creating and
      using sample tables with time series and otherwise</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createSampleTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createSampleTable(tableName:String,baseTable:Option[String],schema:org.apache.spark.sql.types.StructType,samplingOptions:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createSampleTable(String,Option[String],StructType,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createSampleTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="baseTable">baseTable: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>, <span name="samplingOptions">samplingOptions: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createSampleTable(tableName:String,baseTable:Option[String],schema:org.apache.spark.sql.types.StructType,samplingOptions:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Create a stratified sample table.</p><div class="fullcomment"><div class="comment cmt"><p>Create a stratified sample table.</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>the qualified name of the table</p></dd><dt class="param">baseTable</dt><dd class="cmt"><p>the base table of the sample table, if any</p></dd><dt class="param">schema</dt><dd class="cmt"><p>schema of the table</p></dd><dt class="param">samplingOptions</dt><dd class="cmt"><p>sampling options like QCS, reservoir size etc.</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd></dl><dl class="attributes block"> <dt>To do</dt><dd><span class="cmt"><p>provide lot more details and examples to explain creating and
      using sample tables with time series and otherwise</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createSampleTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createSampleTable(tableName:String,baseTable:String,samplingOptions:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createSampleTable(String,String,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createSampleTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="baseTable">baseTable: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="samplingOptions">samplingOptions: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createSampleTable(tableName:String,baseTable:String,samplingOptions:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Create a stratified sample table.</p><div class="fullcomment"><div class="comment cmt"><p>Create a stratified sample table. Java friendly version.</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>the qualified name of the table</p></dd><dt class="param">baseTable</dt><dd class="cmt"><p>the base table of the sample table, if any, or null</p></dd><dt class="param">samplingOptions</dt><dd class="cmt"><p>sampling options like QCS, reservoir size etc.</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd></dl><dl class="attributes block"> <dt>To do</dt><dd><span class="cmt"><p>provide lot more details and examples to explain creating and
      using sample tables with time series and otherwise</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createSampleTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createSampleTable(tableName:String,baseTable:Option[String],samplingOptions:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createSampleTable(String,Option[String],Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createSampleTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="baseTable">baseTable: <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="samplingOptions">samplingOptions: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createSampleTable(tableName:String,baseTable:Option[String],samplingOptions:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Create a stratified sample table.</p><div class="fullcomment"><div class="comment cmt"><p>Create a stratified sample table.</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>the qualified name of the table</p></dd><dt class="param">baseTable</dt><dd class="cmt"><p>the base table of the sample table, if any</p></dd><dt class="param">samplingOptions</dt><dd class="cmt"><p>sampling options like QCS, reservoir size etc.</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd></dl><dl class="attributes block"> <dt>To do</dt><dd><span class="cmt"><p>provide lot more details and examples to explain creating and
      using sample tables with time series and otherwise</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createTable(tableName:String,provider:String,schemaDDL:String,options:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createTable(String,String,String,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="provider">provider: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="schemaDDL">schemaDDL: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createTable(tableName:String,provider:String,schemaDDL:String,options:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Creates a SnappyData managed JDBC table which takes a free format ddl
string.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a SnappyData managed JDBC table which takes a free format ddl
string. The ddl string should adhere to syntax of underlying JDBC store.
SnappyData ships with inbuilt JDBC store, which can be accessed by
Row format data store. The option parameter can take connection details.</p><pre>   <span class="kw">val</span> props = <span class="std">Map</span>(
     <span class="lit">"url"</span> -&gt; s<span class="lit">"jdbc:derby:$path"</span>,
     <span class="lit">"driver"</span> -&gt; <span class="lit">"org.apache.derby.jdbc.EmbeddedDriver"</span>,
     <span class="lit">"poolImpl"</span> -&gt; <span class="lit">"tomcat"</span>,
     <span class="lit">"user"</span> -&gt; <span class="lit">"app"</span>,
     <span class="lit">"password"</span> -&gt; <span class="lit">"app"</span>
   )

<span class="kw">val</span> schemaDDL = <span class="lit">"(OrderId INT NOT NULL PRIMARY KEY,ItemId INT, ITEMREF INT)"</span>
snappyContext.createTable(<span class="lit">"jdbcTable"</span>, <span class="lit">"jdbc"</span>, schemaDDL, props)</pre><p>Any DataFrame of the same schema can be inserted into the JDBC table using
DataFrameWriter API.</p><p>e.g.</p><pre><span class="kw">case</span> <span class="kw">class</span> Data(col1: <span class="std">Int</span>, col2: <span class="std">Int</span>, col3: <span class="std">Int</span>)

<span class="kw">val</span> data = <span class="std">Seq</span>(<span class="std">Seq</span>(<span class="num">1</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">7</span>, <span class="num">8</span>, <span class="num">9</span>), <span class="std">Seq</span>(<span class="num">9</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">4</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">5</span>, <span class="num">6</span>, <span class="num">7</span>))
<span class="kw">val</span> rdd = sc.parallelize(data, data.length).map(s <span class="kw">=&gt;</span> <span class="kw">new</span> Data(s(<span class="num">0</span>), s(<span class="num">1</span>), s(<span class="num">2</span>)))
<span class="kw">val</span> dataDF = snc.createDataFrame(rdd)
dataDF.write.insertInto(<span class="lit">"jdbcTable"</span>)</pre></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>Name of the table</p></dd><dt class="param">provider</dt><dd class="cmt"><p>Provider name 'ROW' or 'JDBC'.</p></dd><dt class="param">schemaDDL</dt><dd class="cmt"><p>Table schema as a string interpreted by provider</p></dd><dt class="param">options</dt><dd class="cmt"><p>Properties for table creation. See options list for different tables.
https://github.com/SnappyDataInc/snappydata/blob/master/docs/rowAndColumnTables.md</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
name is present, else it will throw table exist exception</p></dd><dt>returns</dt><dd class="cmt"><p>DataFrame for the table</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createTable(tableName:String,provider:String,schemaDDL:String,options:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createTable(String,String,String,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="provider">provider: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="schemaDDL">schemaDDL: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createTable(tableName:String,provider:String,schemaDDL:String,options:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Creates a SnappyData managed JDBC table which takes a free format ddl
string.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a SnappyData managed JDBC table which takes a free format ddl
string. The ddl string should adhere to syntax of underlying JDBC store.
SnappyData ships with inbuilt JDBC store, which can be accessed by
Row format data store. The option parameter can take connection details.</p><pre>   <span class="kw">val</span> props = <span class="std">Map</span>(
     <span class="lit">"url"</span> -&gt; s<span class="lit">"jdbc:derby:$path"</span>,
     <span class="lit">"driver"</span> -&gt; <span class="lit">"org.apache.derby.jdbc.EmbeddedDriver"</span>,
     <span class="lit">"poolImpl"</span> -&gt; <span class="lit">"tomcat"</span>,
     <span class="lit">"user"</span> -&gt; <span class="lit">"app"</span>,
     <span class="lit">"password"</span> -&gt; <span class="lit">"app"</span>
   )

<span class="kw">val</span> schemaDDL = <span class="lit">"(OrderId INT NOT NULL PRIMARY KEY,ItemId INT, ITEMREF INT)"</span>
snappyContext.createTable(<span class="lit">"jdbcTable"</span>, <span class="lit">"jdbc"</span>, schemaDDL, props)</pre><p>Any DataFrame of the same schema can be inserted into the JDBC table using
DataFrameWriter API.</p><p>e.g.</p><pre><span class="kw">case</span> <span class="kw">class</span> Data(col1: <span class="std">Int</span>, col2: <span class="std">Int</span>, col3: <span class="std">Int</span>)

<span class="kw">val</span> data = <span class="std">Seq</span>(<span class="std">Seq</span>(<span class="num">1</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">7</span>, <span class="num">8</span>, <span class="num">9</span>), <span class="std">Seq</span>(<span class="num">9</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">4</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">5</span>, <span class="num">6</span>, <span class="num">7</span>))
<span class="kw">val</span> rdd = sc.parallelize(data, data.length).map(s <span class="kw">=&gt;</span> <span class="kw">new</span> Data(s(<span class="num">0</span>), s(<span class="num">1</span>), s(<span class="num">2</span>)))
<span class="kw">val</span> dataDF = snc.createDataFrame(rdd)
dataDF.write.insertInto(<span class="lit">"jdbcTable"</span>)</pre></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>Name of the table</p></dd><dt class="param">provider</dt><dd class="cmt"><p>Provider name 'ROW' or 'JDBC'.</p></dd><dt class="param">schemaDDL</dt><dd class="cmt"><p>Table schema as a string interpreted by provider</p></dd><dt class="param">options</dt><dd class="cmt"><p>Properties for table creation. See options list for different tables.
https://github.com/SnappyDataInc/snappydata/blob/master/docs/rowAndColumnTables.md</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
name is present, else it will throw table exist exception</p></dd><dt>returns</dt><dd class="cmt"><p>DataFrame for the table</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createTable(tableName:String,provider:String,schema:org.apache.spark.sql.types.StructType,options:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createTable(String,String,StructType,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="provider">provider: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createTable(tableName:String,provider:String,schema:org.apache.spark.sql.types.StructType,options:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Creates a SnappyData managed table.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a SnappyData managed table. Any relation providers
(e.g. row, column etc) supported by SnappyData can be created here.</p><pre><span class="kw">case</span> <span class="kw">class</span> Data(col1: <span class="std">Int</span>, col2: <span class="std">Int</span>, col3: <span class="std">Int</span>)
<span class="kw">val</span> props = <span class="std">Map</span>.empty[<span class="std">String</span>, <span class="std">String</span>]
<span class="kw">val</span> data = <span class="std">Seq</span>(<span class="std">Seq</span>(<span class="num">1</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">7</span>, <span class="num">8</span>, <span class="num">9</span>), <span class="std">Seq</span>(<span class="num">9</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">4</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">5</span>, <span class="num">6</span>, <span class="num">7</span>))
<span class="kw">val</span> rdd = sc.parallelize(data, data.length).map(s <span class="kw">=&gt;</span> <span class="kw">new</span> Data(s(<span class="num">0</span>), s(<span class="num">1</span>), s(<span class="num">2</span>)))
<span class="kw">val</span> dataDF = snc.createDataFrame(rdd)
snappyContext.createTable(tableName, <span class="lit">"column"</span>, dataDF.schema, props)</pre><p>For other external relation providers, use createExternalTable.</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>Name of the table</p></dd><dt class="param">provider</dt><dd class="cmt"><p>Provider name such as 'COLUMN', 'ROW', 'JDBC' etc.</p></dd><dt class="param">schema</dt><dd class="cmt"><p>Table schema</p></dd><dt class="param">options</dt><dd class="cmt"><p>Properties for table creation. See options list for different tables.
https://github.com/SnappyDataInc/snappydata/blob/master/docs/rowAndColumnTables.md</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd><dt>returns</dt><dd class="cmt"><p>DataFrame for the table</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createTable(tableName:String,provider:String,schema:org.apache.spark.sql.types.StructType,options:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createTable(String,String,StructType,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="provider">provider: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createTable(tableName:String,provider:String,schema:org.apache.spark.sql.types.StructType,options:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Creates a SnappyData managed table.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a SnappyData managed table. Any relation providers
(e.g. row, column etc) supported by SnappyData can be created here.</p><pre><span class="kw">case</span> <span class="kw">class</span> Data(col1: <span class="std">Int</span>, col2: <span class="std">Int</span>, col3: <span class="std">Int</span>)
<span class="kw">val</span> props = <span class="std">Map</span>.empty[<span class="std">String</span>, <span class="std">String</span>]
<span class="kw">val</span> data = <span class="std">Seq</span>(<span class="std">Seq</span>(<span class="num">1</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">7</span>, <span class="num">8</span>, <span class="num">9</span>), <span class="std">Seq</span>(<span class="num">9</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">4</span>, <span class="num">2</span>, <span class="num">3</span>), <span class="std">Seq</span>(<span class="num">5</span>, <span class="num">6</span>, <span class="num">7</span>))
<span class="kw">val</span> rdd = sc.parallelize(data, data.length).map(s <span class="kw">=&gt;</span> <span class="kw">new</span> Data(s(<span class="num">0</span>), s(<span class="num">1</span>), s(<span class="num">2</span>)))
<span class="kw">val</span> dataDF = snc.createDataFrame(rdd)
snappyContext.createTable(tableName, <span class="lit">"column"</span>, dataDF.schema, props)</pre><p>For other external relation providers, use createExternalTable.</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>Name of the table</p></dd><dt class="param">provider</dt><dd class="cmt"><p>Provider name such as 'COLUMN', 'ROW', 'JDBC' etc.</p></dd><dt class="param">schema</dt><dd class="cmt"><p>Table schema</p></dd><dt class="param">options</dt><dd class="cmt"><p>Properties for table creation. See options list for different tables.
             https://github.com/SnappyDataInc/snappydata/blob/master/docs/rowAndColumnTables.md</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd><dt>returns</dt><dd class="cmt"><p>DataFrame for the table</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createTable(tableName:String,provider:String,options:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createTable(String,String,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="provider">provider: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createTable(tableName:String,provider:String,options:java.util.Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Creates a SnappyData managed table.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a SnappyData managed table. Any relation providers
(e.g. row, column etc) supported by SnappyData can be created here.</p><pre><span class="kw">val</span> airlineDF = snappyContext.createTable(stagingAirline,
  <span class="lit">"column"</span>, <span class="std">Map</span>(<span class="lit">"buckets"</span> -&gt; <span class="lit">"29"</span>))</pre><p>For other external relation providers, use createExternalTable.</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>Name of the table</p></dd><dt class="param">provider</dt><dd class="cmt"><p>Provider name such as 'COLUMN', 'ROW', 'JDBC', 'PARQUET' etc.</p></dd><dt class="param">options</dt><dd class="cmt"><p>Properties for table creation</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd><dt>returns</dt><dd class="cmt"><p>DataFrame for the table</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#createTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="createTable(tableName:String,provider:String,options:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame"></a>
      <a id="createTable(String,String,Map[String,String],Boolean):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="provider">provider: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@createTable(tableName:String,provider:String,options:Map[String,String],allowExisting:Boolean):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Creates a SnappyData managed table.</p><div class="fullcomment"><div class="comment cmt"><p>Creates a SnappyData managed table. Any relation providers
(e.g. row, column etc) supported by SnappyData can be created here.</p><pre><span class="kw">val</span> airlineDF = snappyContext.createTable(stagingAirline,
  <span class="lit">"column"</span>, <span class="std">Map</span>(<span class="lit">"buckets"</span> -&gt; <span class="lit">"29"</span>))</pre><p>For other external relation providers, use createExternalTable.</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>Name of the table</p></dd><dt class="param">provider</dt><dd class="cmt"><p>Provider name such as 'COLUMN', 'ROW', 'JDBC', 'PARQUET' etc.</p></dd><dt class="param">options</dt><dd class="cmt"><p>Properties for table creation</p></dd><dt class="param">allowExisting</dt><dd class="cmt"><p>When set to true it will ignore if a table with the same
                     name is present, else it will throw table exist exception</p></dd><dt>returns</dt><dd class="cmt"><p>DataFrame for the table</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#delete" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="delete(tableName:String,filterExpr:String):Int"></a>
      <a id="delete(String,String):Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">delete</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="filterExpr">filterExpr: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@delete(tableName:String,filterExpr:String):Int" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Delete all rows in table that match passed filter expression
</p><div class="fullcomment"><div class="comment cmt"><p>Delete all rows in table that match passed filter expression
</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>table name</p></dd><dt class="param">filterExpr</dt><dd class="cmt"><p>SQL WHERE criteria to select rows that will be updated</p></dd><dt>returns</dt><dd class="cmt"><p>number of rows deleted</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/DeveloperApi.html" class="extype" name="org.apache.spark.annotation.DeveloperApi">DeveloperApi</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#dropIndex" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="dropIndex(indexName:String,ifExists:Boolean):Unit"></a>
      <a id="dropIndex(String,Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">dropIndex</span><span class="params">(<span name="indexName">indexName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="ifExists">ifExists: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@dropIndex(indexName:String,ifExists:Boolean):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Drops an index on a table</p><div class="fullcomment"><div class="comment cmt"><p>Drops an index on a table</p></div><dl class="paramcmts block"><dt class="param">indexName</dt><dd class="cmt"><p>Index name which goes in catalog</p></dd><dt class="param">ifExists</dt><dd class="cmt"><p>Drop if exists, else exit gracefully</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#dropTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="dropTable(tableName:String,ifExists:Boolean):Unit"></a>
      <a id="dropTable(String,Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">dropTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="ifExists">ifExists: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@dropTable(tableName:String,ifExists:Boolean):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Drop a SnappyData table created by a call to SnappyContext.createTable,
createExternalTable or registerTempTable.</p><div class="fullcomment"><div class="comment cmt"><p>Drop a SnappyData table created by a call to SnappyContext.createTable,
createExternalTable or registerTempTable.
</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>table to be dropped</p></dd><dt class="param">ifExists</dt><dd class="cmt"><p>attempt drop only if the table exists</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#dropTempTable" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="dropTempTable(tableName:String):Unit"></a>
      <a id="dropTempTable(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">dropTempTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@dropTempTable(tableName:String):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Drops the temporary table with the given table name in the catalog.</p><div class="fullcomment"><div class="comment cmt"><p>Drops the temporary table with the given table name in the catalog. If the table has been
cached/persisted before, it's also unpersisted.
</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>the name of the table to be unregistered.</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#emptyDataFrame" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="emptyDataFrame:org.apache.spark.sql.DataFrame"></a>
      <a id="emptyDataFrame:DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">emptyDataFrame</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@emptyDataFrame:org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns a <code>DataFrame</code> with no rows or columns.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a <code>DataFrame</code> with no rows or columns.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="scala.AnyRef#eq" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="eq(x$1:AnyRef):Boolean"></a>
      <a id="eq(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: <a href="../../../../scala/package.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@eq(x$1:AnyRef):Boolean" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#equals" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="equals(x$1:Any):Boolean"></a>
      <a id="equals(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@equals(x$1:Any):Boolean" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#experimental" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="experimental:org.apache.spark.sql.ExperimentalMethods"></a>
      <a id="experimental:ExperimentalMethods"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">experimental</span><span class="result">: <a href="ExperimentalMethods.html" class="extype" name="org.apache.spark.sql.ExperimentalMethods">ExperimentalMethods</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@experimental:org.apache.spark.sql.ExperimentalMethods" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
A collection of methods that are considered experimental, but can be used to hook into
the query planner for advanced functionality.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
A collection of methods that are considered experimental, but can be used to hook into
the query planner for advanced functionality.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@transient</span><span class="args">()</span>
              
                <span class="name">@Unstable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="scala.AnyRef#finalize" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="finalize():Unit"></a>
      <a id="finalize():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@finalize():Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="symbol">classOf[java.lang.Throwable]</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#getAllConfs" visbl="pub" data-isabs="false" fullComment="yes" group="config">
      <a id="getAllConfs:scala.collection.immutable.Map[String,String]"></a>
      <a id="getAllConfs:Map[String,String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getAllConfs</span><span class="result">: <span class="extype" name="scala.collection.immutable.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@getAllConfs:scala.collection.immutable.Map[String,String]" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Return all the configuration properties that have been set (i.e.</p><div class="fullcomment"><div class="comment cmt"><p>Return all the configuration properties that have been set (i.e. not the default).
This creates a new copy of the config properties in the form of a Map.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.0.0</p></dd></dl></div>
    </li><li name="scala.AnyRef#getClass" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getClass():Class[_]"></a>
      <a id="getClass():Class[_]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: <span class="extype" name="java.lang.Class">Class</span>[_]</span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@getClass():Class[_]" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#getConf" visbl="pub" data-isabs="false" fullComment="yes" group="config">
      <a id="getConf(key:String,defaultValue:String):String"></a>
      <a id="getConf(String,String):String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getConf</span><span class="params">(<span name="key">key: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="defaultValue">defaultValue: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Predef.String">String</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@getConf(key:String,defaultValue:String):String" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Return the value of Spark SQL configuration property for the given key.</p><div class="fullcomment"><div class="comment cmt"><p>Return the value of Spark SQL configuration property for the given key. If the key is not set
yet, return <code>defaultValue</code>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#getConf" visbl="pub" data-isabs="false" fullComment="yes" group="config">
      <a id="getConf(key:String):String"></a>
      <a id="getConf(String):String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getConf</span><span class="params">(<span name="key">key: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Predef.String">String</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@getConf(key:String):String" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Return the value of Spark SQL configuration property for the given key.</p><div class="fullcomment"><div class="comment cmt"><p>Return the value of Spark SQL configuration property for the given key.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.0.0</p></dd></dl></div>
    </li><li name="scala.AnyRef#hashCode" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="hashCode():Int"></a>
      <a id="hashCode():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">hashCode</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@hashCode():Int" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext.implicits" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="implicits"></a>
      <a id="implicits:implicits"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a href="SQLContext$implicits$.html"><span class="name">implicits</span></a><span class="result"> extends <a href="SQLImplicits.html" class="extype" name="org.apache.spark.sql.SQLImplicits">SQLImplicits</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SQLContext@implicits" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
(Scala-specific) Implicit methods available in Scala for converting
common Scala objects into <code>DataFrame</code>s.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
(Scala-specific) Implicit methods available in Scala for converting
common Scala objects into <code>DataFrame</code>s.</p><pre><span class="kw">val</span> sqlContext = <span class="kw">new</span> SQLContext(sc)
<span class="kw">import</span> sqlContext.implicits._</pre></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#initializeLogIfNecessary" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="initializeLogIfNecessary(isInterpreter:Boolean):Unit"></a>
      <a id="initializeLogIfNecessary(Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">initializeLogIfNecessary</span><span class="params">(<span name="isInterpreter">isInterpreter: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@initializeLogIfNecessary(isInterpreter:Boolean):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#insert" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="insert(tableName:String,rows:java.util.ArrayList[java.util.ArrayList[_]]):Int"></a>
      <a id="insert(String,ArrayList[ArrayList[_]]):Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">insert</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="rows">rows: <span class="extype" name="java.util.ArrayList">ArrayList</span>[<span class="extype" name="java.util.ArrayList">ArrayList</span>[_]]</span>)</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@insert(tableName:String,rows:java.util.ArrayList[java.util.ArrayList[_]]):Int" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Insert one or more <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">org.apache.spark.sql.Row</a> into an existing table</p><div class="fullcomment"><div class="comment cmt"><p>Insert one or more <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">org.apache.spark.sql.Row</a> into an existing table</p><pre>java.util.ArrayList[java.util.ArrayList[_] rows = ...    *
snc.insert(tableName, rows)</pre></div><dl class="paramcmts block"><dt>returns</dt><dd class="cmt"><p>number of rows inserted</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#insert" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="insert(tableName:String,rows:org.apache.spark.sql.Row*):Int"></a>
      <a id="insert(String,Row*):Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">insert</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="rows">rows: <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>*</span>)</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@insert(tableName:String,rows:org.apache.spark.sql.Row*):Int" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Insert one or more <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">org.apache.spark.sql.Row</a> into an existing table</p><div class="fullcomment"><div class="comment cmt"><p>Insert one or more <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">org.apache.spark.sql.Row</a> into an existing table</p><pre>snc.insert(tableName, dataDF.collect(): _*)</pre></div><dl class="paramcmts block"><dt>returns</dt><dd class="cmt"><p>number of rows inserted</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/DeveloperApi.html" class="extype" name="org.apache.spark.annotation.DeveloperApi">DeveloperApi</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#isCached" visbl="pub" data-isabs="false" fullComment="yes" group="cachemgmt">
      <a id="isCached(tableName:String):Boolean"></a>
      <a id="isCached(String):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isCached</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@isCached(tableName:String):Boolean" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns true if the table is currently cached in-memory.</p><div class="fullcomment"><div class="comment cmt"><p>Returns true if the table is currently cached in-memory.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="scala.Any#isInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <a id="isInstanceOf[T0]:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@isInstanceOf[T0]:Boolean" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#isTraceEnabled" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="isTraceEnabled():Boolean"></a>
      <a id="isTraceEnabled():Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isTraceEnabled</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@isTraceEnabled():Boolean" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#listenerManager" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="listenerManager:org.apache.spark.sql.util.ExecutionListenerManager"></a>
      <a id="listenerManager:ExecutionListenerManager"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">listenerManager</span><span class="result">: <a href="util/ExecutionListenerManager.html" class="extype" name="org.apache.spark.sql.util.ExecutionListenerManager">ExecutionListenerManager</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@listenerManager:org.apache.spark.sql.util.ExecutionListenerManager" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">An interface to register custom <a href="util/QueryExecutionListener.html" class="extype" name="org.apache.spark.sql.util.QueryExecutionListener">org.apache.spark.sql.util.QueryExecutionListener</a>s
that listen for execution metrics.</p><div class="fullcomment"><div class="comment cmt"><p>An interface to register custom <a href="util/QueryExecutionListener.html" class="extype" name="org.apache.spark.sql.util.QueryExecutionListener">org.apache.spark.sql.util.QueryExecutionListener</a>s
that listen for execution metrics.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#log" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="log:org.slf4j.Logger"></a>
      <a id="log:Logger"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">log</span><span class="result">: <span class="extype" name="org.slf4j.Logger">Logger</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@log:org.slf4j.Logger" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#logDebug" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logDebug(msg:=&gt;String,throwable:Throwable):Unit"></a>
      <a id="logDebug(⇒String,Throwable):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logDebug</span><span class="params">(<span name="msg">msg: ⇒ <span class="extype" name="scala.Predef.String">String</span></span>, <span name="throwable">throwable: <a href="../../../../scala/package.html#Throwable=Throwable" class="extmbr" name="scala.Throwable">Throwable</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@logDebug(msg:=&gt;String,throwable:Throwable):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#logDebug" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logDebug(msg:=&gt;String):Unit"></a>
      <a id="logDebug(⇒String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logDebug</span><span class="params">(<span name="msg">msg: ⇒ <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@logDebug(msg:=&gt;String):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#logError" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logError(msg:=&gt;String,throwable:Throwable):Unit"></a>
      <a id="logError(⇒String,Throwable):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logError</span><span class="params">(<span name="msg">msg: ⇒ <span class="extype" name="scala.Predef.String">String</span></span>, <span name="throwable">throwable: <a href="../../../../scala/package.html#Throwable=Throwable" class="extmbr" name="scala.Throwable">Throwable</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@logError(msg:=&gt;String,throwable:Throwable):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#logError" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logError(msg:=&gt;String):Unit"></a>
      <a id="logError(⇒String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logError</span><span class="params">(<span name="msg">msg: ⇒ <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@logError(msg:=&gt;String):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#logInfo" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logInfo(msg:=&gt;String,throwable:Throwable):Unit"></a>
      <a id="logInfo(⇒String,Throwable):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logInfo</span><span class="params">(<span name="msg">msg: ⇒ <span class="extype" name="scala.Predef.String">String</span></span>, <span name="throwable">throwable: <a href="../../../../scala/package.html#Throwable=Throwable" class="extmbr" name="scala.Throwable">Throwable</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@logInfo(msg:=&gt;String,throwable:Throwable):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#logInfo" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logInfo(msg:=&gt;String):Unit"></a>
      <a id="logInfo(⇒String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logInfo</span><span class="params">(<span name="msg">msg: ⇒ <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@logInfo(msg:=&gt;String):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#logName" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logName:String"></a>
      <a id="logName:String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logName</span><span class="result">: <span class="extype" name="java.lang.String">String</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@logName:String" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#logTrace" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logTrace(msg:=&gt;String,throwable:Throwable):Unit"></a>
      <a id="logTrace(⇒String,Throwable):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logTrace</span><span class="params">(<span name="msg">msg: ⇒ <span class="extype" name="scala.Predef.String">String</span></span>, <span name="throwable">throwable: <a href="../../../../scala/package.html#Throwable=Throwable" class="extmbr" name="scala.Throwable">Throwable</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@logTrace(msg:=&gt;String,throwable:Throwable):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#logTrace" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logTrace(msg:=&gt;String):Unit"></a>
      <a id="logTrace(⇒String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logTrace</span><span class="params">(<span name="msg">msg: ⇒ <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@logTrace(msg:=&gt;String):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#logWarning" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logWarning(msg:=&gt;String,throwable:Throwable):Unit"></a>
      <a id="logWarning(⇒String,Throwable):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logWarning</span><span class="params">(<span name="msg">msg: ⇒ <span class="extype" name="scala.Predef.String">String</span></span>, <span name="throwable">throwable: <a href="../../../../scala/package.html#Throwable=Throwable" class="extmbr" name="scala.Throwable">Throwable</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@logWarning(msg:=&gt;String,throwable:Throwable):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="org.apache.spark.internal.Logging#logWarning" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logWarning(msg:=&gt;String):Unit"></a>
      <a id="logWarning(⇒String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logWarning</span><span class="params">(<span name="msg">msg: ⇒ <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@logWarning(msg:=&gt;String):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li name="scala.AnyRef#ne" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ne(x$1:AnyRef):Boolean"></a>
      <a id="ne(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: <a href="../../../../scala/package.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@ne(x$1:AnyRef):Boolean" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#newSession" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="newSession():org.apache.spark.sql.SnappyContext"></a>
      <a id="newSession():SnappyContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">newSession</span><span class="params">()</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.SnappyContext">SnappyContext</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@newSession():org.apache.spark.sql.SnappyContext" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns a <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a> as new session, with separated SQL configurations, temporary
tables, registered functions, but sharing the same <code>SparkContext</code>, cached data and
other things.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a> as new session, with separated SQL configurations, temporary
tables, registered functions, but sharing the same <code>SparkContext</code>, cached data and
other things.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.SnappyContext">SnappyContext</a> → <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="scala.AnyRef#notify" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notify():Unit"></a>
      <a id="notify():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@notify():Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notifyAll" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notifyAll():Unit"></a>
      <a id="notifyAll():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@notifyAll():Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#put" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="put(tableName:String,rows:java.util.ArrayList[java.util.ArrayList[_]]):Int"></a>
      <a id="put(String,ArrayList[ArrayList[_]]):Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">put</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="rows">rows: <span class="extype" name="java.util.ArrayList">ArrayList</span>[<span class="extype" name="java.util.ArrayList">ArrayList</span>[_]]</span>)</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@put(tableName:String,rows:java.util.ArrayList[java.util.ArrayList[_]]):Int" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Upsert one or more <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">org.apache.spark.sql.Row</a> into an existing table</p><div class="fullcomment"><div class="comment cmt"><p>Upsert one or more <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">org.apache.spark.sql.Row</a> into an existing table</p><pre>java.util.ArrayList[java.util.ArrayList[_] rows = ...    *
 snSession.put(tableName, rows)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#put" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="put(tableName:String,rows:org.apache.spark.sql.Row*):Int"></a>
      <a id="put(String,Row*):Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">put</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="rows">rows: <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>*</span>)</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@put(tableName:String,rows:org.apache.spark.sql.Row*):Int" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Upsert one or more <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">org.apache.spark.sql.Row</a> into an existing table</p><div class="fullcomment"><div class="comment cmt"><p>Upsert one or more <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">org.apache.spark.sql.Row</a> into an existing table</p><pre>snSession.put(tableName, dataDF.collect(): _*)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/DeveloperApi.html" class="extype" name="org.apache.spark.annotation.DeveloperApi">DeveloperApi</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#queryApproxTSTopK" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="queryApproxTSTopK(topK:String,startTime:Long,endTime:Long,k:Int):org.apache.spark.sql.DataFrame"></a>
      <a id="queryApproxTSTopK(String,Long,Long,Int):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">queryApproxTSTopK</span><span class="params">(<span name="topK">topK: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="startTime">startTime: <span class="extype" name="scala.Long">Long</span></span>, <span name="endTime">endTime: <span class="extype" name="scala.Long">Long</span></span>, <span name="k">k: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@queryApproxTSTopK(topK:String,startTime:Long,endTime:Long,k:Int):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      
    </li><li name="org.apache.spark.sql.SnappyContext#queryApproxTSTopK" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="queryApproxTSTopK(topKName:String,startTime:Long,endTime:Long):org.apache.spark.sql.DataFrame"></a>
      <a id="queryApproxTSTopK(String,Long,Long):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">queryApproxTSTopK</span><span class="params">(<span name="topKName">topKName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="startTime">startTime: <span class="extype" name="scala.Long">Long</span></span>, <span name="endTime">endTime: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@queryApproxTSTopK(topKName:String,startTime:Long,endTime:Long):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>To do</dt><dd><span class="cmt"><p>why do we need this method? K is optional in the above method</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#queryApproxTSTopK" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="queryApproxTSTopK(topKName:String,startTime:String,endTime:String,k:Int):org.apache.spark.sql.DataFrame"></a>
      <a id="queryApproxTSTopK(String,String,String,Int):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">queryApproxTSTopK</span><span class="params">(<span name="topKName">topKName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="startTime">startTime: <span class="extype" name="scala.Predef.String">String</span> = <span class="symbol">null</span></span>, <span name="endTime">endTime: <span class="extype" name="scala.Predef.String">String</span> = <span class="symbol">null</span></span>, <span name="k">k: <span class="extype" name="scala.Int">Int</span> = <span class="symbol">1</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@queryApproxTSTopK(topKName:String,startTime:String,endTime:String,k:Int):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Fetch the topK entries in the Approx TopK synopsis for the specified
time interval.</p><div class="fullcomment"><div class="comment cmt"><p>Fetch the topK entries in the Approx TopK synopsis for the specified
time interval. See _createTopK_ for how to create this data structure
and associate this to a base table (i.e. the full data set). The time
interval specified here should not be less than the minimum time interval
used when creating the TopK synopsis.</p></div><dl class="paramcmts block"><dt class="param">topKName</dt><dd class="cmt"><p>- The topK structure that is to be queried.</p></dd><dt class="param">startTime</dt><dd class="cmt"><p>start time as string of the format &quot;yyyy-mm-dd hh:mm:ss&quot;.
                 If passed as null, oldest interval is considered as the start interval.</p></dd><dt class="param">endTime</dt><dd class="cmt"><p>end time as string of the format &quot;yyyy-mm-dd hh:mm:ss&quot;.
                If passed as null, newest interval is considered as the last interval.</p></dd><dt class="param">k</dt><dd class="cmt"><p>Optional. Number of elements to be queried.
         This is to be passed only for stream summary</p></dd><dt>returns</dt><dd class="cmt"><p>returns the top K elements with their respective frequencies between two time</p></dd></dl><dl class="attributes block"> <dt>To do</dt><dd><span class="cmt"><p>provide an example and explain the returned DataFrame. Key is the
      attribute stored but the value is a struct containing
      count_estimate, and lower, upper bounds? How many elements are
      returned if K is not specified?</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#range" visbl="pub" data-isabs="false" fullComment="yes" group="dataframe">
      <a id="range(start:Long,end:Long,step:Long,numPartitions:Int):org.apache.spark.sql.DataFrame"></a>
      <a id="range(Long,Long,Long,Int):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">range</span><span class="params">(<span name="start">start: <span class="extype" name="scala.Long">Long</span></span>, <span name="end">end: <span class="extype" name="scala.Long">Long</span></span>, <span name="step">step: <span class="extype" name="scala.Long">Long</span></span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@range(start:Long,end:Long,step:Long,numPartitions:Int):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
Creates a <code>DataFrame</code> with a single <span class="extype" name="LongType">LongType</span> column named <code>id</code>, containing elements
in an range from <code>start</code> to <code>end</code> (exclusive) with an step value, with partition number
specified.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a <code>DataFrame</code> with a single <span class="extype" name="LongType">LongType</span> column named <code>id</code>, containing elements
in an range from <code>start</code> to <code>end</code> (exclusive) with an step value, with partition number
specified.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#range" visbl="pub" data-isabs="false" fullComment="yes" group="dataframe">
      <a id="range(start:Long,end:Long,step:Long):org.apache.spark.sql.DataFrame"></a>
      <a id="range(Long,Long,Long):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">range</span><span class="params">(<span name="start">start: <span class="extype" name="scala.Long">Long</span></span>, <span name="end">end: <span class="extype" name="scala.Long">Long</span></span>, <span name="step">step: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@range(start:Long,end:Long,step:Long):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
Creates a <code>DataFrame</code> with a single <span class="extype" name="LongType">LongType</span> column named <code>id</code>, containing elements
in a range from <code>start</code> to <code>end</code> (exclusive) with a step value.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a <code>DataFrame</code> with a single <span class="extype" name="LongType">LongType</span> column named <code>id</code>, containing elements
in a range from <code>start</code> to <code>end</code> (exclusive) with a step value.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#range" visbl="pub" data-isabs="false" fullComment="yes" group="dataframe">
      <a id="range(start:Long,end:Long):org.apache.spark.sql.DataFrame"></a>
      <a id="range(Long,Long):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">range</span><span class="params">(<span name="start">start: <span class="extype" name="scala.Long">Long</span></span>, <span name="end">end: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@range(start:Long,end:Long):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
Creates a <code>DataFrame</code> with a single <span class="extype" name="LongType">LongType</span> column named <code>id</code>, containing elements
in a range from <code>start</code> to <code>end</code> (exclusive) with step value 1.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a <code>DataFrame</code> with a single <span class="extype" name="LongType">LongType</span> column named <code>id</code>, containing elements
in a range from <code>start</code> to <code>end</code> (exclusive) with step value 1.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#range" visbl="pub" data-isabs="false" fullComment="yes" group="dataframe">
      <a id="range(end:Long):org.apache.spark.sql.DataFrame"></a>
      <a id="range(Long):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">range</span><span class="params">(<span name="end">end: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@range(end:Long):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
Creates a <code>DataFrame</code> with a single <span class="extype" name="LongType">LongType</span> column named <code>id</code>, containing elements
in a range from 0 to <code>end</code> (exclusive) with step value 1.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a <code>DataFrame</code> with a single <span class="extype" name="LongType">LongType</span> column named <code>id</code>, containing elements
in a range from 0 to <code>end</code> (exclusive) with step value 1.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.1</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#read" visbl="pub" data-isabs="false" fullComment="yes" group="genericdata">
      <a id="read:org.apache.spark.sql.DataFrameReader"></a>
      <a id="read:DataFrameReader"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">read</span><span class="result">: <a href="DataFrameReader.html" class="extype" name="org.apache.spark.sql.DataFrameReader">DataFrameReader</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@read:org.apache.spark.sql.DataFrameReader" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns a <a href="DataFrameReader.html" class="extype" name="org.apache.spark.sql.DataFrameReader">DataFrameReader</a> that can be used to read non-streaming data in as a
<code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a <a href="DataFrameReader.html" class="extype" name="org.apache.spark.sql.DataFrameReader">DataFrameReader</a> that can be used to read non-streaming data in as a
<code>DataFrame</code>.</p><pre>sqlContext.read.parquet(<span class="lit">"/path/to/file.parquet"</span>)
sqlContext.read.schema(schema).json(<span class="lit">"/path/to/file.json"</span>)</pre></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#readStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="readStream:org.apache.spark.sql.streaming.DataStreamReader"></a>
      <a id="readStream:DataStreamReader"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">readStream</span><span class="result">: <a href="streaming/DataStreamReader.html" class="extype" name="org.apache.spark.sql.streaming.DataStreamReader">DataStreamReader</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@readStream:org.apache.spark.sql.streaming.DataStreamReader" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: Experimental ::
Returns a <span class="extype" name="DataStreamReader">DataStreamReader</span> that can be used to read streaming data in as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Returns a <span class="extype" name="DataStreamReader">DataStreamReader</span> that can be used to read streaming data in as a <code>DataFrame</code>.</p><pre>sparkSession.readStream.parquet(<span class="lit">"/path/to/directory/of/parquet/files"</span>)
sparkSession.readStream.schema(schema).json(<span class="lit">"/path/to/directory/of/json/files"</span>)</pre></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
                <span class="name">@Evolving</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#saveStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveStream[T](stream:org.apache.spark.streaming.dstream.DStream[T],aqpTables:Seq[String],transformer:Option[org.apache.spark.rdd.RDD[T]=&gt;org.apache.spark.rdd.RDD[org.apache.spark.sql.Row]])(implicitv:reflect.runtime.universe.TypeTag[T]):Unit"></a>
      <a id="saveStream[T](DStream[T],Seq[String],Option[(RDD[T])⇒RDD[Row]])(scala.reflect.api.JavaUniverse.TypeTag[T]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="stream">stream: <a href="../streaming/dstream/DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[<span class="extype" name="org.apache.spark.sql.SnappyContext.saveStream.T">T</span>]</span>, <span name="aqpTables">aqpTables: <a href="../../../../scala/package.html#Seq[+A]=Seq[A]" class="extmbr" name="scala.Seq">Seq</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="transformer">transformer: <span class="extype" name="scala.Option">Option</span>[(<a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="org.apache.spark.sql.SnappyContext.saveStream.T">T</span>]) ⇒ <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="v">v: <span class="extype" name="scala.reflect.api.TypeTags.TypeTag">scala.reflect.api.JavaUniverse.TypeTag</span>[<span class="extype" name="org.apache.spark.sql.SnappyContext.saveStream.T">T</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@saveStream[T](stream:org.apache.spark.streaming.dstream.DStream[T],aqpTables:Seq[String],transformer:Option[org.apache.spark.rdd.RDD[T]=&gt;org.apache.spark.rdd.RDD[org.apache.spark.sql.Row]])(implicitv:reflect.runtime.universe.TypeTag[T]):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">:: DeveloperApi ::</p><div class="fullcomment"><div class="comment cmt"><p>:: DeveloperApi ::</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/DeveloperApi.html" class="extype" name="org.apache.spark.annotation.DeveloperApi">DeveloperApi</a></span><span class="args">()</span>
              
        </dd><dt>To do</dt><dd><span class="cmt"><p>do we need this anymore? If useful functionality, make this
      private to sql package ... SchemaDStream should use the data source
      API?
      Tagging as developer API, for now</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#sessionState" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="sessionState:org.apache.spark.sql.hive.SnappySessionState"></a>
      <a id="sessionState:SnappySessionState"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sessionState</span><span class="result">: <a href="hive/SnappySessionState.html" class="extype" name="org.apache.spark.sql.hive.SnappySessionState">SnappySessionState</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@sessionState:org.apache.spark.sql.hive.SnappySessionState" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.SnappyContext">SnappyContext</a> → <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#setConf" visbl="pub" data-isabs="false" fullComment="yes" group="config">
      <a id="setConf(key:String,value:String):Unit"></a>
      <a id="setConf(String,String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">setConf</span><span class="params">(<span name="key">key: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="value">value: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@setConf(key:String,value:String):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Set the given Spark SQL configuration property.</p><div class="fullcomment"><div class="comment cmt"><p>Set the given Spark SQL configuration property.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#setConf" visbl="pub" data-isabs="false" fullComment="yes" group="config">
      <a id="setConf(props:java.util.Properties):Unit"></a>
      <a id="setConf(Properties):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">setConf</span><span class="params">(<span name="props">props: <span class="extype" name="java.util.Properties">Properties</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@setConf(props:java.util.Properties):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Set Spark SQL configuration properties.</p><div class="fullcomment"><div class="comment cmt"><p>Set Spark SQL configuration properties.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#setCurrentSchema" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="setCurrentSchema(schemaName:String):Unit"></a>
      <a id="setCurrentSchema(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">setCurrentSchema</span><span class="params">(<span name="schemaName">schemaName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@setCurrentSchema(schemaName:String):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Set current database/schema.</p><div class="fullcomment"><div class="comment cmt"><p>Set current database/schema.
</p></div><dl class="paramcmts block"><dt class="param">schemaName</dt><dd class="cmt"><p>schema name which goes in the catalog</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#snappySession" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="snappySession:org.apache.spark.sql.SnappySession"></a>
      <a id="snappySession:SnappySession"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">snappySession</span><span class="result">: <a href="SnappySession.html" class="extype" name="org.apache.spark.sql.SnappySession">SnappySession</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@snappySession:org.apache.spark.sql.SnappySession" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      
    </li><li name="org.apache.spark.sql.SQLContext#sparkContext" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="sparkContext:org.apache.spark.SparkContext"></a>
      <a id="sparkContext:SparkContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sparkContext</span><span class="result">: <a href="../SparkContext.html" class="extype" name="org.apache.spark.SparkContext">SparkContext</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@sparkContext:org.apache.spark.SparkContext" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#sparkSession" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="sparkSession:org.apache.spark.sql.SparkSession"></a>
      <a id="sparkSession:SparkSession"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">sparkSession</span><span class="result">: <a href="SparkSession.html" class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@sparkSession:org.apache.spark.sql.SparkSession" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#sql" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="sql(sqlText:String):org.apache.spark.sql.DataFrame"></a>
      <a id="sql(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sql</span><span class="params">(<span name="sqlText">sqlText: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@sql(sqlText:String):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Executes a SQL query using Spark, returning the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Executes a SQL query using Spark, returning the result as a <code>DataFrame</code>. The dialect that is
used for SQL parsing can be configured with 'spark.sql.dialect'.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#sqlUncached" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="sqlUncached(sqlText:String):org.apache.spark.sql.DataFrame"></a>
      <a id="sqlUncached(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sqlUncached</span><span class="params">(<span name="sqlText">sqlText: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@sqlUncached(sqlText:String):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Run SQL string without any plan caching.</p>
    </li><li name="org.apache.spark.sql.SQLContext#streams" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="streams:org.apache.spark.sql.streaming.StreamingQueryManager"></a>
      <a id="streams:StreamingQueryManager"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">streams</span><span class="result">: <a href="streaming/StreamingQueryManager.html" class="extype" name="org.apache.spark.sql.streaming.StreamingQueryManager">StreamingQueryManager</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@streams:org.apache.spark.sql.streaming.StreamingQueryManager" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns a <span class="extype" name="StreamingQueryManager">StreamingQueryManager</span> that allows managing all the
<a href="streaming/StreamingQuery.html" class="extype" name="org.apache.spark.sql.streaming.StreamingQuery">StreamingQueries</a> active on <code>this</code> context.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a <span class="extype" name="StreamingQueryManager">StreamingQueryManager</span> that allows managing all the
<a href="streaming/StreamingQuery.html" class="extype" name="org.apache.spark.sql.streaming.StreamingQuery">StreamingQueries</a> active on <code>this</code> context.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="scala.AnyRef#synchronized" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="synchronized[T0](x$1:=&gt;T0):T0"></a>
      <a id="synchronized[T0](⇒T0):T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>)</span><span class="result">: <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@synchronized[T0](x$1:=&gt;T0):T0" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#table" visbl="pub" data-isabs="false" fullComment="yes" group="ddl_ops">
      <a id="table(tableName:String):org.apache.spark.sql.DataFrame"></a>
      <a id="table(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">table</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@table(tableName:String):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns the specified table as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the specified table as a <code>DataFrame</code>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#tableNames" visbl="pub" data-isabs="false" fullComment="yes" group="ddl_ops">
      <a id="tableNames(databaseName:String):Array[String]"></a>
      <a id="tableNames(String):Array[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">tableNames</span><span class="params">(<span name="databaseName">databaseName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@tableNames(databaseName:String):Array[String]" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns the names of tables in the given database as an array.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the names of tables in the given database as an array.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#tableNames" visbl="pub" data-isabs="false" fullComment="yes" group="ddl_ops">
      <a id="tableNames():Array[String]"></a>
      <a id="tableNames():Array[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">tableNames</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@tableNames():Array[String]" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns the names of tables in the current database as an array.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the names of tables in the current database as an array.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#tables" visbl="pub" data-isabs="false" fullComment="yes" group="ddl_ops">
      <a id="tables(databaseName:String):org.apache.spark.sql.DataFrame"></a>
      <a id="tables(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">tables</span><span class="params">(<span name="databaseName">databaseName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@tables(databaseName:String):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns a <code>DataFrame</code> containing names of existing tables in the given database.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a <code>DataFrame</code> containing names of existing tables in the given database.
The returned DataFrame has two columns, tableName and isTemporary (a Boolean
indicating if a table is a temporary one or not).
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#tables" visbl="pub" data-isabs="false" fullComment="yes" group="ddl_ops">
      <a id="tables():org.apache.spark.sql.DataFrame"></a>
      <a id="tables():DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">tables</span><span class="params">()</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@tables():org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns a <code>DataFrame</code> containing names of existing tables in the current database.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a <code>DataFrame</code> containing names of existing tables in the current database.
The returned DataFrame has two columns, tableName and isTemporary (a Boolean
indicating if a table is a temporary one or not).
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="scala.AnyRef#toString" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="toString():String"></a>
      <a id="toString():String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toString</span><span class="params">()</span><span class="result">: <span class="extype" name="java.lang.String">String</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@toString():String" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#truncateTable" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="truncateTable(tableName:String,ifExists:Boolean):Unit"></a>
      <a id="truncateTable(String,Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">truncateTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="ifExists">ifExists: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">false</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@truncateTable(tableName:String,ifExists:Boolean):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Empties the contents of the table without deleting the catalog entry.</p><div class="fullcomment"><div class="comment cmt"><p>Empties the contents of the table without deleting the catalog entry.
</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>full table name to be truncated</p></dd><dt class="param">ifExists</dt><dd class="cmt"><p>attempt truncate only if the table exists</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#udf" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="udf:org.apache.spark.sql.UDFRegistration"></a>
      <a id="udf:UDFRegistration"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">udf</span><span class="result">: <a href="UDFRegistration.html" class="extype" name="org.apache.spark.sql.UDFRegistration">UDFRegistration</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@udf:org.apache.spark.sql.UDFRegistration" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">A collection of methods for registering user-defined functions (UDF).</p><div class="fullcomment"><div class="comment cmt"><p>A collection of methods for registering user-defined functions (UDF).</p><p>The following example registers a Scala closure as UDF:</p><pre>sqlContext.udf.register(<span class="lit">"myUDF"</span>, (arg1: <span class="std">Int</span>, arg2: <span class="std">String</span>) <span class="kw">=&gt;</span> arg2 + arg1)</pre><p>The following example registers a UDF in Java:</p><pre>sqlContext.udf().register(<span class="lit">"myUDF"</span>,
    <span class="kw">new</span> UDF2&lt;Integer, <span class="std">String</span>, <span class="std">String</span>&gt;() {
        @Override
        public <span class="std">String</span> call(Integer arg1, <span class="std">String</span> arg2) {
            <span class="kw">return</span> arg2 + arg1;
        }
   }, DataTypes.StringType);</pre><p>Or, to use Java 8 lambda syntax:</p><pre>sqlContext.udf().register(<span class="lit">"myUDF"</span>,
    (Integer arg1, <span class="std">String</span> arg2) -&gt; arg2 + arg1,
    DataTypes.StringType);</pre></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd><dt>Note</dt><dd><span class="cmt"><p>The user-defined functions must be deterministic. Due to optimization,
duplicate invocations may be eliminated or the function may even be invoked more times than
it is present in the query.</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#uncacheTable" visbl="pub" data-isabs="false" fullComment="yes" group="cachemgmt">
      <a id="uncacheTable(tableName:String):Unit"></a>
      <a id="uncacheTable(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">uncacheTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@uncacheTable(tableName:String):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Removes the specified table from the in-memory cache.</p><div class="fullcomment"><div class="comment cmt"><p>Removes the specified table from the in-memory cache.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#update" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="update(tableName:String,filterExpr:String,newColumnValues:java.util.ArrayList[_],updateColumns:java.util.ArrayList[String]):Int"></a>
      <a id="update(String,String,ArrayList[_],ArrayList[String]):Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">update</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="filterExpr">filterExpr: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="newColumnValues">newColumnValues: <span class="extype" name="java.util.ArrayList">ArrayList</span>[_]</span>, <span name="updateColumns">updateColumns: <span class="extype" name="java.util.ArrayList">ArrayList</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@update(tableName:String,filterExpr:String,newColumnValues:java.util.ArrayList[_],updateColumns:java.util.ArrayList[String]):Int" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Update all rows in table that match passed filter expression</p><div class="fullcomment"><div class="comment cmt"><p>Update all rows in table that match passed filter expression</p><pre>snappyContext.update(<span class="lit">"jdbcTable"</span>, <span class="lit">"ITEMREF = 3"</span> , Row(<span class="num">99</span>) , <span class="lit">"ITEMREF"</span> )</pre></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>table name which needs to be updated</p></dd><dt class="param">filterExpr</dt><dd class="cmt"><p>SQL WHERE criteria to select rows that will be updated</p></dd><dt class="param">newColumnValues</dt><dd class="cmt"><p>A list containing all the updated column
                       values. They MUST match the updateColumn list
                       passed</p></dd><dt class="param">updateColumns</dt><dd class="cmt"><p>List of all column names being updated</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SnappyContext#update" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="update(tableName:String,filterExpr:String,newColumnValues:org.apache.spark.sql.Row,updateColumns:String*):Int"></a>
      <a id="update(String,String,Row,String*):Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">update</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="filterExpr">filterExpr: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="newColumnValues">newColumnValues: <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a></span>, <span name="updateColumns">updateColumns: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@update(tableName:String,filterExpr:String,newColumnValues:org.apache.spark.sql.Row,updateColumns:String*):Int" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Update all rows in table that match passed filter expression</p><div class="fullcomment"><div class="comment cmt"><p>Update all rows in table that match passed filter expression</p><pre>snappyContext.update(<span class="lit">"jdbcTable"</span>, <span class="lit">"ITEMREF = 3"</span> , Row(<span class="num">99</span>) , <span class="lit">"ITEMREF"</span> )</pre></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>table name which needs to be updated</p></dd><dt class="param">filterExpr</dt><dd class="cmt"><p>SQL WHERE criteria to select rows that will be updated</p></dd><dt class="param">newColumnValues</dt><dd class="cmt"><p>A single Row containing all updated column
                        values. They MUST match the updateColumn list
                        passed</p></dd><dt class="param">updateColumns</dt><dd class="cmt"><p>List of all column names being updated</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/DeveloperApi.html" class="extype" name="org.apache.spark.annotation.DeveloperApi">DeveloperApi</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait():Unit"></a>
      <a id="wait():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@wait():Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long,x$2:Int):Unit"></a>
      <a id="wait(Long,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>, <span name="arg1">arg1: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@wait(x$1:Long,x$2:Int):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long):Unit"></a>
      <a id="wait(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@wait(x$1:Long):Unit" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li></ol>
            </div>

        

        <div id="values" class="values members">
              <h3>Deprecated Value Members</h3>
              <ol><li name="org.apache.spark.sql.SQLContext#applySchema" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="applySchema(rdd:org.apache.spark.api.java.JavaRDD[_],beanClass:Class[_]):org.apache.spark.sql.DataFrame"></a>
      <a id="applySchema(JavaRDD[_],Class[_]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.3.0) Use createDataFrame instead.">applySchema</span><span class="params">(<span name="rdd">rdd: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[_]</span>, <span name="beanClass">beanClass: <span class="extype" name="scala.Predef.Class">Class</span>[_]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@applySchema(rdd:org.apache.spark.api.java.JavaRDD[_],beanClass:Class[_]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.3.0)</i> Use createDataFrame instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#applySchema" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="applySchema(rdd:org.apache.spark.rdd.RDD[_],beanClass:Class[_]):org.apache.spark.sql.DataFrame"></a>
      <a id="applySchema(RDD[_],Class[_]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.3.0) Use createDataFrame instead.">applySchema</span><span class="params">(<span name="rdd">rdd: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[_]</span>, <span name="beanClass">beanClass: <span class="extype" name="scala.Predef.Class">Class</span>[_]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@applySchema(rdd:org.apache.spark.rdd.RDD[_],beanClass:Class[_]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.3.0)</i> Use createDataFrame instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#applySchema" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="applySchema(rowRDD:org.apache.spark.api.java.JavaRDD[org.apache.spark.sql.Row],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame"></a>
      <a id="applySchema(JavaRDD[Row],StructType):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.3.0) Use createDataFrame instead.">applySchema</span><span class="params">(<span name="rowRDD">rowRDD: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@applySchema(rowRDD:org.apache.spark.api.java.JavaRDD[org.apache.spark.sql.Row],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.3.0)</i> Use createDataFrame instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#applySchema" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="applySchema(rowRDD:org.apache.spark.rdd.RDD[org.apache.spark.sql.Row],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame"></a>
      <a id="applySchema(RDD[Row],StructType):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.3.0) Use createDataFrame instead.">applySchema</span><span class="params">(<span name="rowRDD">rowRDD: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@applySchema(rowRDD:org.apache.spark.rdd.RDD[org.apache.spark.sql.Row],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.3.0)</i> Use createDataFrame instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jdbc" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jdbc(url:String,table:String,theParts:Array[String]):org.apache.spark.sql.DataFrame"></a>
      <a id="jdbc(String,String,Array[String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.jdbc() instead.">jdbc</span><span class="params">(<span name="url">url: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="table">table: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="theParts">theParts: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jdbc(url:String,table:String,theParts:Array[String]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
url named table.</p><div class="fullcomment"><div class="comment cmt"><p>Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
url named table. The theParts parameter gives a list expressions
suitable for inclusion in WHERE clauses; each one defines one partition
of the <code>DataFrame</code>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.jdbc() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jdbc" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jdbc(url:String,table:String,columnName:String,lowerBound:Long,upperBound:Long,numPartitions:Int):org.apache.spark.sql.DataFrame"></a>
      <a id="jdbc(String,String,String,Long,Long,Int):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.jdbc() instead.">jdbc</span><span class="params">(<span name="url">url: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="table">table: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="columnName">columnName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="lowerBound">lowerBound: <span class="extype" name="scala.Long">Long</span></span>, <span name="upperBound">upperBound: <span class="extype" name="scala.Long">Long</span></span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jdbc(url:String,table:String,columnName:String,lowerBound:Long,upperBound:Long,numPartitions:Int):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
url named table.</p><div class="fullcomment"><div class="comment cmt"><p>Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
url named table.  Partitions of the table will be retrieved in parallel based on the parameters
passed to this function.
</p></div><dl class="paramcmts block"><dt class="param">columnName</dt><dd class="cmt"><p>the name of a column of integral type that will be used for partitioning.</p></dd><dt class="param">lowerBound</dt><dd class="cmt"><p>the minimum value of <code>columnName</code> used to decide partition stride</p></dd><dt class="param">upperBound</dt><dd class="cmt"><p>the maximum value of <code>columnName</code> used to decide partition stride</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>the number of partitions.  the range <code>minValue</code>-<code>maxValue</code> will be split
                     evenly into this many partitions</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.jdbc() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jdbc" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jdbc(url:String,table:String):org.apache.spark.sql.DataFrame"></a>
      <a id="jdbc(String,String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.jdbc() instead.">jdbc</span><span class="params">(<span name="url">url: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="table">table: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jdbc(url:String,table:String):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
url named table.</p><div class="fullcomment"><div class="comment cmt"><p>Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
url named table.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.jdbc() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jsonFile" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jsonFile(path:String,samplingRatio:Double):org.apache.spark.sql.DataFrame"></a>
      <a id="jsonFile(String,Double):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.json() instead.">jsonFile</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="samplingRatio">samplingRatio: <span class="extype" name="scala.Double">Double</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jsonFile(path:String,samplingRatio:Double):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.json() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jsonFile" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jsonFile(path:String,schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame"></a>
      <a id="jsonFile(String,StructType):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.json() instead.">jsonFile</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jsonFile(path:String,schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Loads a JSON file (one object per line) and applies the given schema,
returning the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads a JSON file (one object per line) and applies the given schema,
returning the result as a <code>DataFrame</code>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.json() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jsonFile" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jsonFile(path:String):org.apache.spark.sql.DataFrame"></a>
      <a id="jsonFile(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.json() instead.">jsonFile</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jsonFile(path:String):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Loads a JSON file (one object per line), returning the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads a JSON file (one object per line), returning the result as a <code>DataFrame</code>.
It goes through the entire dataset once to determine the schema.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.json() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jsonRDD" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jsonRDD(json:org.apache.spark.api.java.JavaRDD[String],samplingRatio:Double):org.apache.spark.sql.DataFrame"></a>
      <a id="jsonRDD(JavaRDD[String],Double):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.json() instead.">jsonRDD</span><span class="params">(<span name="json">json: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="samplingRatio">samplingRatio: <span class="extype" name="scala.Double">Double</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jsonRDD(json:org.apache.spark.api.java.JavaRDD[String],samplingRatio:Double):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Loads a JavaRDD[String] storing JSON objects (one object per record) inferring the
schema, returning the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads a JavaRDD[String] storing JSON objects (one object per record) inferring the
schema, returning the result as a <code>DataFrame</code>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.json() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jsonRDD" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jsonRDD(json:org.apache.spark.rdd.RDD[String],samplingRatio:Double):org.apache.spark.sql.DataFrame"></a>
      <a id="jsonRDD(RDD[String],Double):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.json() instead.">jsonRDD</span><span class="params">(<span name="json">json: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="samplingRatio">samplingRatio: <span class="extype" name="scala.Double">Double</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jsonRDD(json:org.apache.spark.rdd.RDD[String],samplingRatio:Double):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Loads an RDD[String] storing JSON objects (one object per record) inferring the
schema, returning the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads an RDD[String] storing JSON objects (one object per record) inferring the
schema, returning the result as a <code>DataFrame</code>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.json() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jsonRDD" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jsonRDD(json:org.apache.spark.api.java.JavaRDD[String],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame"></a>
      <a id="jsonRDD(JavaRDD[String],StructType):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.json() instead.">jsonRDD</span><span class="params">(<span name="json">json: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jsonRDD(json:org.apache.spark.api.java.JavaRDD[String],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Loads an JavaRDD[String] storing JSON objects (one object per record) and applies the given
schema, returning the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads an JavaRDD[String] storing JSON objects (one object per record) and applies the given
schema, returning the result as a <code>DataFrame</code>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.json() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jsonRDD" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jsonRDD(json:org.apache.spark.rdd.RDD[String],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame"></a>
      <a id="jsonRDD(RDD[String],StructType):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.json() instead.">jsonRDD</span><span class="params">(<span name="json">json: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jsonRDD(json:org.apache.spark.rdd.RDD[String],schema:org.apache.spark.sql.types.StructType):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Loads an RDD[String] storing JSON objects (one object per record) and applies the given schema,
returning the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads an RDD[String] storing JSON objects (one object per record) and applies the given schema,
returning the result as a <code>DataFrame</code>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.json() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jsonRDD" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jsonRDD(json:org.apache.spark.api.java.JavaRDD[String]):org.apache.spark.sql.DataFrame"></a>
      <a id="jsonRDD(JavaRDD[String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.json() instead.">jsonRDD</span><span class="params">(<span name="json">json: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jsonRDD(json:org.apache.spark.api.java.JavaRDD[String]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
<code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
<code>DataFrame</code>.
It goes through the entire dataset once to determine the schema.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.json() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#jsonRDD" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="jsonRDD(json:org.apache.spark.rdd.RDD[String]):org.apache.spark.sql.DataFrame"></a>
      <a id="jsonRDD(RDD[String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.json() instead.">jsonRDD</span><span class="params">(<span name="json">json: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@jsonRDD(json:org.apache.spark.rdd.RDD[String]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
<code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
<code>DataFrame</code>.
It goes through the entire dataset once to determine the schema.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.json() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#load" visbl="pub" data-isabs="false" fullComment="yes" group="genericdata">
      <a id="load(source:String,schema:org.apache.spark.sql.types.StructType,options:Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="load(String,StructType,Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.format(source).schema(schema).options(options).load() instead.">load</span><span class="params">(<span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@load(source:String,schema:org.apache.spark.sql.types.StructType,options:Map[String,String]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">(Scala-specific) Returns the dataset specified by the given data source and
a set of options as a DataFrame, using the given schema as the schema of the DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Returns the dataset specified by the given data source and
a set of options as a DataFrame, using the given schema as the schema of the DataFrame.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.format(source).schema(schema).options(options).load() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#load" visbl="pub" data-isabs="false" fullComment="yes" group="genericdata">
      <a id="load(source:String,schema:org.apache.spark.sql.types.StructType,options:java.util.Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="load(String,StructType,Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.format(source).schema(schema).options(options).load() instead.">load</span><span class="params">(<span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="schema">schema: <a href="types/StructType.html" class="extype" name="org.apache.spark.sql.types.StructType">StructType</a></span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@load(source:String,schema:org.apache.spark.sql.types.StructType,options:java.util.Map[String,String]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">(Java-specific) Returns the dataset specified by the given data source and
a set of options as a DataFrame, using the given schema as the schema of the DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>(Java-specific) Returns the dataset specified by the given data source and
a set of options as a DataFrame, using the given schema as the schema of the DataFrame.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.format(source).schema(schema).options(options).load() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#load" visbl="pub" data-isabs="false" fullComment="yes" group="genericdata">
      <a id="load(source:String,options:Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="load(String,Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.format(source).options(options).load() instead.">load</span><span class="params">(<span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@load(source:String,options:Map[String,String]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">(Scala-specific) Returns the dataset specified by the given data source and
a set of options as a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Returns the dataset specified by the given data source and
a set of options as a DataFrame.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.format(source).options(options).load() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#load" visbl="pub" data-isabs="false" fullComment="yes" group="genericdata">
      <a id="load(source:String,options:java.util.Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="load(String,Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.format(source).options(options).load() instead.">load</span><span class="params">(<span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@load(source:String,options:java.util.Map[String,String]):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">(Java-specific) Returns the dataset specified by the given data source and
a set of options as a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>(Java-specific) Returns the dataset specified by the given data source and
a set of options as a DataFrame.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.format(source).options(options).load() instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#load" visbl="pub" data-isabs="false" fullComment="yes" group="genericdata">
      <a id="load(path:String,source:String):org.apache.spark.sql.DataFrame"></a>
      <a id="load(String,String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.format(source).load(path) instead.">load</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@load(path:String,source:String):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns the dataset stored at path as a DataFrame, using the given data source.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the dataset stored at path as a DataFrame, using the given data source.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.format(source).load(path) instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#load" visbl="pub" data-isabs="false" fullComment="yes" group="genericdata">
      <a id="load(path:String):org.apache.spark.sql.DataFrame"></a>
      <a id="load(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.load(path) instead.">load</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@load(path:String):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Returns the dataset stored at path as a DataFrame,
using the default data source configured by spark.sql.sources.default.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the dataset stored at path as a DataFrame,
using the default data source configured by spark.sql.sources.default.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.load(path) instead.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext#parquetFile" visbl="pub" data-isabs="false" fullComment="yes" group="specificdata">
      <a id="parquetFile(paths:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="parquetFile(String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.4.0) Use read.parquet() instead.">parquetFile</span><span class="params">(<span name="paths">paths: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="package.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" class="extmbr" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4><span class="permalink">
      <a href="../../../../index.html#org.apache.spark.sql.SnappyContext@parquetFile(paths:String*):org.apache.spark.sql.DataFrame" title="Permalink" target="_top">
        <img src="../../../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Loads a Parquet file, returning the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads a Parquet file, returning the result as a <code>DataFrame</code>. This function returns an empty
<code>DataFrame</code> if no paths are passed in.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></dd><dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.4.0)</i> Use read.parquet() instead.</p></dd></dl></div>
    </li></ol>
            </div>
        </div>

        <div id="inheritedMembers">
        <div class="parent" name="org.apache.spark.sql.SQLContext">
              <h3>Inherited from <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></h3>
            </div><div class="parent" name="scala.Serializable">
              <h3>Inherited from <span class="extype" name="scala.Serializable">Serializable</span></h3>
            </div><div class="parent" name="java.io.Serializable">
              <h3>Inherited from <span class="extype" name="java.io.Serializable">Serializable</span></h3>
            </div><div class="parent" name="org.apache.spark.internal.Logging">
              <h3>Inherited from <span class="extype" name="org.apache.spark.internal.Logging">internal.Logging</span></h3>
            </div><div class="parent" name="scala.AnyRef">
              <h3>Inherited from <a href="../../../../scala/package.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></h3>
            </div><div class="parent" name="scala.Any">
              <h3>Inherited from <span class="extype" name="scala.Any">Any</span></h3>
            </div>
        
        </div>

        <div id="groupedMembers">
        <div class="group" name="basic">
              <h3>Basic Operations</h3>
              
            </div><div class="group" name="cachemgmt">
              <h3>Cached Table Management</h3>
              
            </div><div class="group" name="config">
              <h3>Configuration</h3>
              
            </div><div class="group" name="dataframe">
              <h3>dataframe</h3>
              
            </div><div class="group" name="dataframes">
              <h3>Custom DataFrame Creation</h3>
              
            </div><div class="group" name="dataset">
              <h3>Custom Dataset Creation</h3>
              
            </div><div class="group" name="ddl_ops">
              <h3>Persistent Catalog DDL</h3>
              
            </div><div class="group" name="genericdata">
              <h3>Generic Data Sources</h3>
              
            </div><div class="group" name="specificdata">
              <h3>Specific Data Sources</h3>
              
            </div><div class="group" name="Ungrouped">
              <h3>Support functions for language integrated queries</h3>
              
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>


    </body>
      </html>
