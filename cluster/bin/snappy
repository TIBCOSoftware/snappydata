#!/usr/bin/env bash

#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

function absPath() {
  perl -MCwd -le 'print Cwd::abs_path(shift)' "$1"
}
if [ -z "${SPARK_HOME}" ]; then
  export SPARK_HOME="$(absPath "$(dirname "$(absPath "$0")")/..")"
fi
export SNAPPY_HOME="${SPARK_HOME}"
# only scala 2.11 supported in SnappyData builds
export SPARK_SCALA_VERSION="2.11"
# disable randomized hash for string in Python 3.3+
export PYTHONHASHSEED=0

if [ -n "`echo "$JAVA_ARGS" | grep -q verbose`" ]; then
  echo "Using JAVA_ARGS=$JAVA_ARGS"
fi


function setnewargs() { newargs="$@"; }

if [ -z "${SNAPPY_SCRIPT_NAME}" ]; then
  export SNAPPY_SCRIPT_NAME=snappy
fi

if echo $@ | grep -qw "rowstore"; then
  #using rowstore launcher
  newargs=
  for arg in "$@"; do
    if [[ "$arg" != "rowstore" ]] ; then
      setnewargs "$newargs" "$arg"
    fi
  done
  exec "$SPARK_HOME"/bin/spark-class $JAVA_ARGS com.pivotal.gemfirexd.tools.GfxdUtilLauncher $newargs
elif [ "$1" = "dataextractor" ]; then
  shift
  exec "$SPARK_HOME"/bin/spark-class $JAVA_ARGS com.pivotal.gemfirexd.tools.dataextractor.GemFireXDDataExtractor "$@"
elif [ "$1" = "dataextractloader" ]; then
  shift
  exec "$SPARK_HOME"/bin/spark-class $JAVA_ARGS com.pivotal.gemfirexd.tools.dataextractor.GemFireXDDataExtractorLoader "$@"
elif [ -z "$SNAPPY_NO_QUICK_LAUNCH" -a $# -ge 2 \
       -a '(' "$2" = "start" -o "$2" = "stop" -o "$2" = "status" ')' \
       -a '(' "$1" = "server" -o "$1" = "leader" -o "$1" = "locator" ')' ]; then
  # faster route for start/stop/status

  # Find the java binary
  if [ -n "${JAVA_HOME}" ]; then
    RUNNER="${JAVA_HOME}/bin/java"
  else
    if [ "$(command -v java)" ]; then
      RUNNER="java"
    else
      echo "JAVA_HOME is not set" >&2
      exit 1
    fi
  fi

  . "${SPARK_HOME}"/bin/load-spark-env.sh
  . "${SPARK_HOME}"/bin/load-snappy-env.sh

  HOSTNAME_FOR_CLIENTS=
  IMPLICIT_AWS_CLIENT_BIND_ADDRESS=
  if [ "$2" = "start" ]; then
    # set hostname-for-clients and SPARK_PUBLIC_DNS in AWS (only supported for Linux)
    if [ -z "$SPARK_PUBLIC_DNS" -o -n "$IMPLICIT_CLIENT_BIND_ADDRESS" ]; then
      CHECK_AWS=1
      if [ -r /sys/hypervisor/uuid ]; then
        if ! grep -q '^ec2' /sys/hypervisor/uuid; then
          CHECK_AWS=
        fi
      elif [ -r /sys/devices/virtual/dmi/id/product_name ]; then
        if ! grep -iq 'hvm' /sys/devices/virtual/dmi/id/product_name; then
          CHECK_AWS=
        fi
      else
        # not running on AWS if neither of those two files are present
        CHECK_AWS=
      fi
      if [ -n "$CHECK_AWS" ]; then
        if [ -z "$SPARK_PUBLIC_DNS" ]; then
          SPARK_PUBLIC_DNS="$(curl -s --connect-timeout 3 http://169.254.169.254/latest/meta-data/public-ipv4 | head -1)"
          if [ -n "$SPARK_PUBLIC_DNS" ]; then
            if ! echo $"${@// /\\ }" | grep -q 'hostname-for-clients='; then
              HOSTNAME_FOR_CLIENTS="-hostname-for-clients=$SPARK_PUBLIC_DNS"
            fi
            export SPARK_PUBLIC_DNS
          fi
        fi
        if [ -n "$IMPLICIT_CLIENT_BIND_ADDRESS" ]; then
          IMPLICIT_AWS_CLIENT_BIND_ADDRESS="-client-bind-address=0.0.0.0"
        fi
      elif [ -n "$IMPLICIT_CLIENT_BIND_ADDRESS" ]; then
        IMPLICIT_AWS_CLIENT_BIND_ADDRESS="-client-bind-address=${IMPLICIT_CLIENT_BIND_ADDRESS}"
        if [ -z "$SPARK_PUBLIC_DNS" ]; then
          HOSTNAME_FOR_CLIENTS="-hostname-for-clients=${IMPLICIT_CLIENT_BIND_ADDRESS}"
          export SPARK_PUBLIC_DNS="${IMPLICIT_CLIENT_BIND_ADDRESS}"
        fi
      elif [ -n "$EXPLICIT_CLIENT_BIND_ADDRESS" -a -z "$SPARK_PUBLIC_DNS" \
             -a "$EXPLICIT_CLIENT_BIND_ADDRESS" != "0.0.0.0" \
             -a "$EXPLICIT_CLIENT_BIND_ADDRESS" != "::0" ]; then
        HOSTNAME_FOR_CLIENTS="-hostname-for-clients=${EXPLICIT_CLIENT_BIND_ADDRESS}"
        export SPARK_PUBLIC_DNS="${EXPLICIT_CLIENT_BIND_ADDRESS}"
      fi
    fi
  fi

  JARS="${SPARK_HOME}/conf:`echo "${SPARK_HOME}"/jars/snappydata-launcher* "${SPARK_HOME}"/jars/gemfire-shared* "${SPARK_HOME}"/jars/log4j-* "${SPARK_HOME}"/jars/jna-4.* | sed 's/ /:/g'`"
  exec $RUNNER $JAVA_ARGS -Xverify:none -cp "$JARS" io.snappydata.tools.QuickLauncher "$@" $HOSTNAME_FOR_CLIENTS $IMPLICIT_AWS_CLIENT_BIND_ADDRESS
  IMPLICIT_CLIENT_BIND_ADDRESS=
  EXPLICIT_CLIENT_BIND_ADDRESS=
else
  # use full snappy launcher
  exec "$SPARK_HOME"/bin/spark-class $JAVA_ARGS io.snappydata.tools.SnappyUtilLauncher "$@"
fi
