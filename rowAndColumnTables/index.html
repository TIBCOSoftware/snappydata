<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="SnappyData Development Team">
  <link rel="shortcut icon" href="../favicon.ico">
  
  <title>Row and Column tables - SnappyData Documentation</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  <link href="../extra.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Row and Column tables";
    var mkdocs_page_input_path = "rowAndColumnTables.md";
    var mkdocs_page_url = "/rowAndColumnTables/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> SnappyData Documentation</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="..">Getting Started</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../build-instructions/">Building from source, project layout</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../snappyIntroduction/">Overview</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../features/">Key features</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../architecture/">Architecture</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../configuration/">Configuring the cluster</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../connectingToCluster/">Connecting using JDBC, Spark</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../jobs/">Developing Apps using the Spark API</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 current">
        <a class="current" href="./">Row and Column tables</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#row-and-column-tables">Row and column tables</a></li>
                
                    <li><a class="toctree-l4" href="#ddl-and-dml-syntax-for-tables">DDL and DML Syntax for tables</a></li>
                
                    <li><a class="toctree-l4" href="#dml-operations-on-tables">DML operations on tables</a></li>
                
            
            </ul>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../aqp/">Synopsis Data Engine (SDE)</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../streamingWithSQL/">Stream processing using SQL</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../deployment/">Deployment topologies</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../apidocsintro/">API</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../aqp_aws/">Using iSight-Cloud</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>About</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../LICENSE/">License</a>
        
    </li>

        
    </ul>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">SnappyData Documentation</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Row and Column tables</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/SnappyDataInc/snappydata/edit/master/docs/rowAndColumnTables.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h3 id="row-and-column-tables">Row and column tables</h3>
<p>Column tables organize and manage data in memory in compressed columnar form such that modern day CPUs can traverse and run computations like a sum or an average really fast (as the values are available in contiguous memory). Column table follows the Spark DataSource access model.</p>
<p>Row tables, unlike column tables, are laid out one row at a time in contiguous memory. Rows are typically accessed using keys and its location determined by a hash function and hence very fast for point lookups or updates.</p>
<p>Create table DDL for Row and Column tables allows tables to be partitioned on primary keys, custom partitioned, replicated, carry indexes in memory, persist to disk, overflow to disk, be replicated for HA, etc.</p>
<h4 id="ddl-and-dml-syntax-for-tables">DDL and DML Syntax for tables</h4>
<pre><code>CREATE TABLE [IF NOT EXISTS] table_name
   (
  COLUMN_DEFININTION
   )
USING 'row | column'
OPTIONS (
COLOCATE_WITH 'table_name',  // Default none
PARTITION_BY 'PRIMARY KEY | column name', // If not specified it will be a replicated table.
BUCKETS  'NumPartitions', // Default 113
REDUNDANCY        '1' ,
RECOVER_DELAY     '-1',
MAX_PART_SIZE      '50',
EVICTION_BY ‘LRUMEMSIZE 200 | LRUCOUNT 200 | LRUHEAPPERCENT,
PERSISTENT  ‘DISKSTORE_NAME ASYNCHRONOUS | SYNCHRONOUS’, //empty string will map to default diskstore
OFFHEAP ‘true | false’ ,
EXPIRE ‘TIMETOLIVE in seconds',
)
[AS select_statement];

DROP TABLE [IF EXISTS] table_name
</code></pre>
<p>For row format tables column definition can take underlying GemFire XD syntax to create a table.e.g.note the PRIMARY KEY clause below.</p>
<pre><code>snc.sql("CREATE TABLE tableName (Col1 INT NOT NULL PRIMARY KEY, Col2 INT, Col3 INT)
         USING row options(BUCKETS '5')" )
</code></pre>
<p>But for column table it's restricted to Spark syntax for column definition e.g.</p>
<pre><code>snc.sql("CREATE TABLE tableName (Col1 INT ,Col2 INT, Col3 INT) USING column options(BUCKETS '5')" )
</code></pre>
<p>Clauses like PRIMARY KEY, NOT NULL etc. are not supported for column definition. </p>
<h5 id="spark-api-for-managing-tables">Spark API for managing tables</h5>
<p>Get a reference to <a href="http://snappydatainc.github.io/snappydata/apidocs/#org.apache.spark.sql.SnappyContext">SnappyContext</a></p>
<pre><code>val snc: SnappyContext = SnappyContext.getOrCreate(sparkContext)
</code></pre>
<p>Create a SnappyStore table using Spark APIs</p>
<pre><code>val props = Map('BUCKETS','5') //This map should contain required DDL extensions, see next section
case class Data(col1: Int, col2: Int, col3: Int)
val data = Seq(Seq(1, 2, 3), Seq(7, 8, 9), Seq(9, 2, 3), Seq(4, 2, 3), Seq(5, 6, 7))
val rdd = sc.parallelize(data, data.length).map(s =&gt; new Data(s(0), s(1), s(2)))
val dataDF = snc.createDataFrame(rdd)
snc.createTable("column_table", "column", dataDF.schema, props)
//or create a row format table
snc.createTable("row_table", "row", dataDF.schema, props)
</code></pre>
<p>Drop a SnappyStore table using Spark APIs</p>
<pre><code>snc.dropTable(tableName, ifExists = true)
</code></pre>
<h5 id="ddl-extensions-to-snappystore-tables">DDL extensions to SnappyStore tables</h5>
<p>The below mentioned DDL extensions are required to configure a table based on user requirements. One can specify one or more options to create the kind of table one wants. If no option is specified, default values are attached. See next section for various restrictions. </p>
<ol>
<li>COLOCATE_WITH  : The COLOCATE_WITH clause specifies a partitioned table with which the new partitioned table must be colocated. The referenced table must already exist.</li>
<li>PARTITION_BY  : Use the PARTITION_BY {COLUMN} clause to provide a set of column names that will determine the partitioning. As a shortcut you can use PARTITION BY PRIMARY KEY to refer to the primary key columns defined for the table . If not specified, it will be a replicated table.</li>
<li>BUCKETS  : The optional BUCKETS attribute specifies the fixed number of "buckets," the smallest unit of data containment for the table that can be moved around. Data in a single bucket resides and moves together. If not specified, the number of buckets defaults to 113.</li>
<li>REDUNDANCY : Use the REDUNDANCY clause to specify the number of redundant copies that should be maintained for each partition, to ensure that the partitioned table is highly available even if members fail.</li>
<li>RECOVER_DELAY : Use the RECOVERY_DELAY clause to specify the default time in milliseconds that existing members will wait before satisfying redundancy after a member crashes. The default is -1, which indicates that redundancy is not recovered after a member fails.</li>
<li>MAX_PART_SIZE : The MAXPARTSIZE attribute specifies the maximum memory for any partition on a member in megabytes. Use it to load-balance partitions among available members. If you omit MAXPARTSIZE, then GemFire XD calculates a default value for the table based on available heap memory. You can view the MAXPARTSIZE setting by querying the EVICTIONATTRS column in SYSTABLES.</li>
<li>EVICTION_BY : Use the EVICTION_BY clause to evict rows automatically from the in-memory table based on different criteria. You can use this clause to create an overflow table where evicted rows are written to a local SnappyStore disk store</li>
<li>PERSISTENT :  When you specify the PERSISTENT keyword, GemFire XD persists the in-memory table data to a local GemFire XD disk store configuration. SnappyStore automatically restores the persisted table data to memory when you restart the member.</li>
<li>OFFHEAP : SnappyStore enables you to store the data for selected tables outside of the JVM heap. Storing a table in off-heap memory can improve performance for the table by reducing the CPU resources required to manage the table's data in the heap (garbage collection)</li>
<li>EXPIRE: You can use the EXPIRE clause with tables to control SnappyStore memory usage. It will expire the rows after configured TTL.</li>
</ol>
<h5 id="restrictions-on-column-tables-in-the-06-release">Restrictions on column tables in the 0.6 release</h5>
<ol>
<li>Column tables can not specify any primary key, unique key constraints.</li>
<li>Index on column table is not supported.</li>
<li>Option EXPIRE is not applicable for column tables.</li>
<li>Option EVICTION_BY with value LRUCOUNT is not applicable for column tables. </li>
</ol>
<h4 id="dml-operations-on-tables">DML operations on tables</h4>
<pre><code>INSERT OVERWRITE TABLE tablename1 select_statement1 FROM from_statement;
INSERT INTO TABLE tablename1 select_statement1 FROM from_statement;
INSERT INTO TABLE tablename1 VALUES (value1, value2 ..) ;
UPDATE tablename SET column = value [, column = value ...] [WHERE expression]
PUT INTO tableName (column, ...) VALUES (value, ...)
DELETE FROM tablename1 [WHERE expression]
TRUNCATE TABLE tablename1;
</code></pre>
<h5 id="api-extensions-provided-in-snappycontext">API extensions provided in SnappyContext</h5>
<p>We have added several APIs in <a href="http://snappydatainc.github.io/snappydata/apidocs/#org.apache.spark.sql.SnappyContext">SnappyContext</a> to manipulate data stored in row and column format. Apart from SQL these APIs can be used to manipulate tables.</p>
<pre><code>//  Applicable for both row &amp; column tables
def insert(tableName: String, rows: Row*): Int .

// Only for row tables
def put(tableName: String, rows: Row*): Int
def update(tableName: String, filterExpr: String, newColumnValues: Row, 
           updateColumns: String*): Int
def delete(tableName: String, filterExpr: String): Int
</code></pre>
<p>Usage SnappyConytext.insert(): Insert one or more [[org.apache.spark.sql.Row]] into an existing table</p>
<pre><code>val data = Seq(Seq(1, 2, 3), Seq(7, 8, 9), Seq(9, 2, 3), Seq(4, 2, 3),
               Seq(5, 6, 7), Seq(1,100,200))
data.map { r =&gt;
  snappyContext.insert("tableName", Row.fromSeq(r))
}
</code></pre>
<p>Usage SnappyConytext.put(): Upsert one or more [[org.apache.spark.sql.Row]] into an existing table</p>
<pre><code>val data = Seq(Seq(1, 2, 3), Seq(7, 8, 9), Seq(9, 2, 3), Seq(4, 2, 3),
               Seq(5, 6, 7), Seq(1,100,200))
data.map { r =&gt;
  snc.put(tableName, Row.fromSeq(r))
}
</code></pre>
<p>Usage SnappyConytext.update(): Update all rows in table that match passed filter expression</p>
<pre><code>snc.update(tableName, "ITEMREF = 3" , Row(99) , "ITEMREF" )
</code></pre>
<p>Usage SnappyConytext.delete(): Delete all rows in table that match passed filter expression</p>
<pre><code>snc.delete(tableName, "ITEMREF = 3")
</code></pre>
<h5 id="row-buffers-for-column-tables">Row Buffers for column tables</h5>
<p>Generally, the Column table is used for analytical purpose. To this end, most of the
operations (read or write) on it are bulk operations. Taking advantage of this fact
the rows are compressed column wise and stored.</p>
<p>In SnappyData, the column table consists of two components, delta row buffer and
column store. We try to support individual insert of single row, we store them in
a delta row buffer which is write optimized and highly available.
Once the size of buffer reaches the COLUMN_BATCH_SIZE set by user, the delta row
buffer is compressed column wise and stored in the column store.</p>
<p>Any query on column table, also takes into account the row cached buffer. By doing
this, we ensure that the query doesn't miss any data.</p>
<h5 id="catalog-in-snappystore">Catalog in SnappyStore</h5>
<p>We use a persistent Hive catalog for all our metadata storage. All table, schema definition are stored here in a reliable manner. As we intend be able to quickly recover from driver failover, we chose GemFireXd itself to store meta information. This gives us ability to query underlying GemFireXD to reconstruct the metastore incase of a driver failover. </p>
<p>There are pending work towards unifying DRDA &amp; Spark layer catalog, which will part of future releases. </p>
<h5 id="sql-reference-to-the-syntax">SQL Reference to the Syntax</h5>
<p>For detailed syntax for GemFire XD check
http://gemfirexd.docs.pivotal.io/docs-gemfirexd/reference/sql-language-reference.html</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../aqp/" class="btn btn-neutral float-right" title="Synopsis Data Engine (SDE)">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../jobs/" class="btn btn-neutral" title="Developing Apps using the Spark API"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright &copy; 2016 SnappyData Inc.</p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/SnappyDataInc/snappydata" class="icon icon-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../jobs/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../aqp/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>

</body>
</html>
