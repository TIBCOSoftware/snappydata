/*
 * Copyright (c) 2017-2019 TIBCO Software Inc. All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License"); you
 * may not use this file except in compliance with the License. You
 * may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 * implied. See the License for the specific language governing
 * permissions and limitations under the License. See accompanying
 * LICENSE file.
 */

apply plugin: 'scala'
apply plugin: 'de.undercouch.download'

compileScala.options.encoding = 'UTF-8'
// fix scala+java mix to all use compileScala which uses correct dependency order
sourceSets.main.scala.srcDir 'src/main/java'
sourceSets.test.scala.srcDirs = [ 'src/test/java', 'src/test/scala',
                                  'src/dunit/java', 'src/dunit/scala' ]
sourceSets.main.java.srcDirs = []
sourceSets.test.java.srcDirs = []

dependencies {
  compileOnly 'org.scala-lang:scala-library:' + scalaVersion
  compileOnly 'org.scala-lang:scala-reflect:' + scalaVersion

  compile 'org.slf4j:slf4j-api:' + slf4jVersion
  compile 'org.slf4j:slf4j-log4j12:' + slf4jVersion
  compile 'org.slf4j:jcl-over-slf4j:' + slf4jVersion
  compile 'org.slf4j:jul-to-slf4j:' + slf4jVersion
  compile group: 'org.codehaus.janino', name: 'janino', version: janinoVersion
  compile("org.apache.thrift:libthrift:${thriftVersion}") {
    exclude(group: 'org.slf4j', module: 'slf4j-api')
  }

  // always use stock spark so that snappy extensions don't get accidently
  // included here in snappy-core code.
  if (System.properties.containsKey('ideaBuild') && new File(rootDir, 'spark/build.gradle').exists()) {
    compile project(':snappy-spark:snappy-spark-core_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-catalyst_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-sql_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-hive_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-streaming_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-streaming-kafka-0.10_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-sql-kafka-0.10_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-mllib_' + scalaBinaryVersion)

    compileOnly "org.eclipse.jetty:jetty-servlet:${jettyVersion}"
    testCompile "org.eclipse.jetty:jetty-servlet:${jettyVersion}"

    testCompile project(path: ':snappy-spark:snappy-spark-core_' + scalaBinaryVersion, configuration: 'testOutput')
    testCompile project(path: ':snappy-spark:snappy-spark-sql_' + scalaBinaryVersion, configuration: 'testOutput')
    testCompile project(path: ':snappy-spark:snappy-spark-streaming_' + scalaBinaryVersion, configuration: 'testOutput')
  } else {
    compile(group: 'com.fasterxml.jackson.module', name: 'jackson-module-scala_' + scalaBinaryVersion, version: jacksonVersion) {
      exclude(group: 'org.scala-lang', module: 'scala-library')
      exclude(group: 'org.scala-lang', module: 'scala-reflect')
      exclude(group: 'com.google.guava', module: 'guava')
    }
    compile(group: 'org.spark-project.hive', name: 'hive-exec', version: hiveVersion) {
      exclude(group: 'org.datanucleus', module: 'datanucleus-core')
      exclude(group: 'org.spark-project.hive', module: 'hive-metastore')
      exclude(group: 'org.spark-project.hive', module: 'hive-shims')
      exclude(group: 'org.spark-project.hive', module: 'hive-ant')
      exclude(group: 'org.spark-project.hive', module: 'spark-client')
      exclude(group: 'org.apache.ant', module: 'ant')
      exclude(group: 'com.esotericsoftware.kryo', module: 'kryo')
      exclude(group: 'commons-codec', module: 'commons-codec')
      exclude(group: 'commons-httpclient', module: 'commons-httpclient')
      exclude(group: 'org.apache.avro', module: 'avro-mapred')
      exclude(group: 'org.apache.calcite', module: 'calcite-core')
      exclude(group: 'org.apache.curator', module: 'apache-curator')
      exclude(group: 'org.apache.curator', module: 'curator-client')
      exclude(group: 'org.apache.curator', module: 'curator-framework')
      exclude(group: 'org.apache.thrift', module: 'libthrift')
      exclude(group: 'org.apache.thrift', module: 'libfb303')
      exclude(group: 'org.apache.zookeeper', module: 'zookeeper')
      exclude(group: 'org.slf4j', module: 'slf4j-api')
      exclude(group: 'org.slf4j', module: 'slf4j-log4j12')
      exclude(group: 'log4j', module: 'log4j')
      exclude(group: 'commons-logging', module: 'commons-logging')
      exclude(group: 'org.codehaus.groovy', module: 'groovy-all')
      exclude(group: 'jline', module: 'jline')
      exclude(group: 'org.json', module: 'json')
    }
    compile(group: 'org.spark-project.hive', name: 'hive-metastore', version: hiveVersion) {
      exclude(group: 'org.datanucleus', module: 'datanucleus-core')
      exclude(group: 'org.datanucleus', module: 'datanucleus-api-jdo')
      exclude(group: 'org.datanucleus', module: 'datanucleus-rdbms')
      exclude(group: 'org.spark-project.hive', module: 'hive-serde')
      exclude(group: 'org.spark-project.hive', module: 'hive-shims')
      exclude(group: 'org.apache.thrift', module: 'libfb303')
      exclude(group: 'org.apache.thrift', module: 'libthrift')
      exclude(group: 'javax.servlet', module: 'servlet-api')
      exclude(group: 'com.google.guava', module: 'guava')
      exclude(group: 'org.slf4j', module: 'slf4j-api')
      exclude(group: 'org.slf4j', module: 'slf4j-log4j12')
      exclude(group: 'log4j', module: 'log4j')
      exclude(group: 'org.apache.derby', module: 'derby')
    }

    compileOnly("org.apache.spark:spark-core_${scalaBinaryVersion}:${sparkVersion}")
    compileOnly("org.apache.spark:spark-catalyst_${scalaBinaryVersion}:${sparkVersion}")
    compileOnly("org.apache.spark:spark-sql_${scalaBinaryVersion}:${sparkVersion}")
    compileOnly("org.apache.spark:spark-hive_${scalaBinaryVersion}:${sparkVersion}")
    compileOnly("org.apache.spark:spark-streaming_${scalaBinaryVersion}:${sparkVersion}")
    compileOnly("org.apache.spark:spark-streaming-kafka-0-10_${scalaBinaryVersion}:${sparkVersion}")
    compileOnly("org.apache.spark:spark-sql-kafka-0-10_${scalaBinaryVersion}:${sparkVersion}")
    compileOnly("org.apache.spark:spark-mllib_${scalaBinaryVersion}:${sparkVersion}")

    compileOnly "org.eclipse.jetty:jetty-servlet:${jettyVersion}"

    testCompile("org.apache.spark:spark-core_${scalaBinaryVersion}:${sparkVersion}")
    testCompile("org.apache.spark:spark-catalyst_${scalaBinaryVersion}:${sparkVersion}")
    testCompile("org.apache.spark:spark-sql_${scalaBinaryVersion}:${sparkVersion}")
    testCompile("org.apache.spark:spark-hive_${scalaBinaryVersion}:${sparkVersion}")
    testCompile("org.apache.spark:spark-streaming_${scalaBinaryVersion}:${sparkVersion}")
    testCompile("org.apache.spark:spark-streaming-kafka-0-10_${scalaBinaryVersion}:${sparkVersion}")
    testCompile("org.apache.spark:spark-sql-kafka-0-10_${scalaBinaryVersion}:${sparkVersion}")
    testCompile("org.apache.spark:spark-mllib_${scalaBinaryVersion}:${sparkVersion}")

    testCompile "org.eclipse.jetty:jetty-servlet:${jettyVersion}"

    testCompile("org.apache.spark:spark-core_${scalaBinaryVersion}:${sparkVersion}:tests")
    testCompile("org.apache.spark:spark-sql_${scalaBinaryVersion}:${sparkVersion}:tests")
    testCompile("org.apache.spark:spark-sql-kafka-0-10_${scalaBinaryVersion}:${sparkVersion}:tests")
    testCompile("org.apache.spark:spark-streaming_${scalaBinaryVersion}:${sparkVersion}:tests")
    testCompile("org.apache.spark:spark-streaming-kafka-0-10_${scalaBinaryVersion}:${sparkVersion}:tests")
  }

  if (new File(rootDir, 'store/build.gradle').exists()) {
    compile project(':snappy-store:snappydata-store-client')
    compile project(':snappy-store:snappydata-store-core')
    compile project(':snappy-store:snappydata-store-tools')
    testCompile project(path: ':snappy-store:snappydata-store-tools', configuration: 'testOutput')
  } else {
    compile group: 'io.snappydata', name: 'snappydata-store-client', version: snappyStoreVersion
    compile group: 'io.snappydata', name: 'snappydata-store-core', version: snappyStoreVersion
    compile group: 'io.snappydata', name: 'snappydata-store-tools', version: snappyStoreVersion
    testCompile group: 'io.snappydata', name: 'snappydata-store-tools', version: snappyStoreVersion, classifier: 'tests'
  }
  compile project(":snappy-jdbc_${scalaBinaryVersion}")
  compile project(":snappy-encoders_${scalaBinaryVersion}")

  compile("org.parboiled:parboiled_${scalaBinaryVersion}:${parboiledVersion}") {
    exclude(group: 'org.scala-lang', module: 'scala-library')
    exclude(group: 'org.scala-lang', module: 'scala-reflect')
    exclude(group: 'org.scala-lang', module: 'scala-compiler')
  }
  compile "org.apache.tomcat:tomcat-juli:${tomcatJdbcVersion}"
  compile "org.apache.tomcat:tomcat-jdbc:${tomcatJdbcVersion}"
  compile "com.zaxxer:HikariCP:${hikariCPVersion}"
  compile "org.twitter4j:twitter4j-stream:${twitter4jVersion}"
  compile "org.objenesis:objenesis:${objenesisVersion}"
  compile "com.esotericsoftware:kryo-shaded:${kryoVersion}"
  compile "it.unimi.dsi:fastutil-core:${fastutilVersion}"

  compileOnly "com.rabbitmq:amqp-client:${rabbitMqVersion}"

  testCompile project(':dunit')
  testCompile 'org.scala-lang:scala-actors:' + scalaVersion
  testCompile "org.scalatest:scalatest_${scalaBinaryVersion}:${scalatestVersion}"

  testRuntime files("${projectDir}/../tests/common/src/main/resources")
  testRuntime "org.pegdown:pegdown:${pegdownVersion}"
  testCompile(project(path: ':snappy-examples_' + scalaBinaryVersion, configuration: 'testOutput')) {
    exclude(group: 'io.snappydata', module: 'snappy-cluster_' + scalaBinaryVersion)
    exclude(group: 'io.snappydata', module: 'snappy-aqp_' + scalaBinaryVersion)
    exclude(group: 'io.snappydata', module: 'gemfire-core')
  }
}

task packageScalaDocs(type: Jar, dependsOn: scaladoc) {
  archiveClassifier.set('javadoc')
  from scaladoc
}
if (rootProject.hasProperty('enablePublish')) {
  artifacts {
    archives packageScalaDocs, packageSources
  }
}

scalaTest {
  dependsOn ':cleanScalaTest'
  doFirst {
    // cleanup files since scalatest plugin does not honour workingDir yet
    cleanIntermediateFiles(project.path)
  }
  doLast {
    // cleanup files since scalatest plugin does not honour workingDir yet
    cleanIntermediateFiles(project.path)
  }
}

def downloadApacheSparkDist(String ver, String distName, String prodDir) {
  return tasks.create("downloadApache${ver}SparkDist", Download) {
    outputs.files "${prodDir}.tgz", "${prodDir}/README.md"

    src "http://archive.apache.org/dist/spark/spark-${ver}/${distName}.tgz"
    dest sparkDistDir
    onlyIfNewer true

    doFirst {
      mkdir(sparkDistDir)
    }
  }
}

def taskGetApacheSparkDist(String ver, String distName, String prodDir) {
  return tasks.create("getApacheSpark${ver}Dist") {
    dependsOn downloadApacheSparkDist(ver, distName, prodDir)

    outputs.files "${prodDir}.tgz", "${prodDir}/README.md"

    doLast {
      if (osName.isWindows()) {
        copy {
          from tarTree(resources.gzip("${sparkDistDir}/${distName}.tgz"))
          into sparkDistDir
        }
      } else {
        // gradle tarTree does not preserve symlinks (GRADLE-2844)
        exec {
          executable 'tar'
          args 'xzf', "${distName}.tgz"
          workingDir = sparkDistDir
        }
      }
    }
  }
}

task getApacheSparkDist {
  dependsOn taskGetApacheSparkDist(sparkVersion, sparkDistName, sparkProductDir)
  dependsOn taskGetApacheSparkDist(sparkCurrentVersion, sparkCurrentDistName, sparkCurrentProductDir)
}

test.dependsOn ':cleanJUnit'
dunitTest.dependsOn getApacheSparkDist
dunitSecurityTest.dependsOn getApacheSparkDist
// SnappyJobTestSupport.getJobJar needs cluster tests
dunitTest.dependsOn ":snappy-cluster_${scalaBinaryVersion}:testClasses"
// SplitClusterDUnitSecurityTest.testSnappyStreamingJob needs cluster tests
dunitSecurityTest.dependsOn ":snappy-cluster_${scalaBinaryVersion}:testClasses"
check.dependsOn test, scalaTest, dunitTest, dunitSecurityTest


archivesBaseName = 'snappydata-core_' + scalaBinaryVersion
