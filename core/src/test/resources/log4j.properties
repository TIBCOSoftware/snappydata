#
# Copyright (c) 2017-2022 TIBCO Software Inc. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License"); you
# may not use this file except in compliance with the License. You
# may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied. See the License for the specific language governing
# permissions and limitations under the License. See accompanying
# LICENSE file.
#
# Some parts taken from Spark's log4j.properties having license below.
#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

log4j.rootCategory=INFO, file

# RollingFile appender
log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.append=true
log4j.appender.file.file=snappydata.log
log4j.appender.file.MaxFileSize=1GB
log4j.appender.file.MaxBackupIndex=10000
log4j.appender.file.layout=io.snappydata.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss.SSS zzz} %t %p %c{1}: %m%n

# Appender for code dumps of WholeStageCodegenExec, CodeGenerator etc
log4j.appender.code=org.apache.log4j.RollingFileAppender
log4j.appender.code.append=true
log4j.appender.code.file=generatedcode.log
log4j.appender.code.MaxFileSize=1GB
log4j.appender.code.MaxBackupIndex=10000
log4j.appender.code.layout=io.snappydata.log4j.PatternLayout
log4j.appender.code.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss.SSS zzz} %t %p %c{1}: %m%n

# Console appender
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.out
log4j.appender.console.layout=io.snappydata.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss.SSS zzz} %t %p %c{1}: %m%n

# Ignore messages below warning level from Jetty, because it's a bit verbose
log4j.logger.org.spark-project.jetty=WARN
org.spark-project.jetty.LEVEL=WARN
log4j.logger.org.mortbay.jetty=WARN
log4j.logger.org.eclipse.jetty=WARN

# Some packages are noisy for no good reason.
log4j.additivity.org.apache.hadoop.hive.serde2.lazy.LazyStruct=false
log4j.logger.org.apache.hadoop.hive.serde2.lazy.LazyStruct=OFF

log4j.additivity.org.apache.hadoop.hive.metastore.RetryingHMSHandler=false
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=OFF

log4j.additivity.hive.log=false
log4j.logger.hive.log=OFF

log4j.additivity.parquet.hadoop.ParquetRecordReader=false
log4j.logger.parquet.hadoop.ParquetRecordReader=OFF

log4j.additivity.org.apache.parquet.hadoop.ParquetRecordReader=false
log4j.logger.org.apache.parquet.hadoop.ParquetRecordReader=OFF

log4j.additivity.org.apache.parquet.hadoop.ParquetOutputCommitter=false
log4j.logger.org.apache.parquet.hadoop.ParquetOutputCommitter=OFF

log4j.additivity.hive.ql.metadata.Hive=false
log4j.logger.hive.ql.metadata.Hive=OFF

log4j.additivity.org.apache.hadoop.hive.ql.io.RCFile=false
log4j.logger.org.apache.hadoop.hive.ql.io.RCFile=ERROR

# Other Spark classes that generate unnecessary logs at INFO level
log4j.logger.org.apache.spark.broadcast.TorrentBroadcast=WARN
log4j.logger.org.apache.spark.ContextCleaner=WARN
log4j.logger.org.apache.spark.MapOutputTracker=WARN
log4j.logger.org.apache.spark.scheduler.TaskSchedulerImpl=WARN
log4j.logger.org.apache.spark.storage.ShuffleBlockFetcherIterator=WARN
log4j.logger.org.apache.spark.scheduler.DAGScheduler=WARN
log4j.logger.org.apache.spark.scheduler.TaskSetManager=WARN
log4j.logger.org.apache.spark.scheduler.FairSchedulableBuilder=WARN
log4j.logger.org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint=WARN
log4j.logger.org.apache.spark.storage.BlockManager=WARN
log4j.logger.org.apache.spark.storage.BlockManagerInfo=WARN
log4j.logger.org.apache.hadoop.hive=WARN
log4j.logger.org.apache.spark.sql.execution.datasources=WARN
log4j.logger.org.apache.spark.scheduler.SnappyTaskSchedulerImpl=WARN
log4j.logger.org.apache.spark.MapOutputTrackerMasterEndpoint=WARN
log4j.logger.org.apache.spark.MapOutputTrackerMaster=WARN
log4j.logger.org.apache.spark.storage.memory.MemoryStore=WARN
log4j.logger.org.apache.spark.MapOutputTrackerWorker=WARN
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR
log4j.logger.org.apache.hadoop.io.compress=WARN
log4j.logger.spark.jobserver.LocalContextSupervisorActor=WARN
log4j.logger.spark.jobserver.JarManager=WARN
log4j.logger.org.datanucleus=ERROR
# Task logger created in SparkEnv
log4j.logger.org.apache.spark.Task=WARN
log4j.logger.org.apache.spark.sql.catalyst.parser.CatalystSqlParser=WARN
# HiveExternalCatalog spits out a warning every time a non-hive table is persisted in meta-store
log4j.logger.org.apache.spark.sql.hive.SnappyHiveExternalCatalog=ERROR

# Keep log-level of some classes as INFO even if root level is higher
log4j.logger.io.snappydata.impl.LeadImpl=INFO
log4j.logger.io.snappydata.impl.ServerImpl=INFO
log4j.logger.io.snappydata.impl.LocatorImpl=INFO
log4j.logger.spray.can.server.HttpListener=INFO

# Note: all code generation classes that dump using "code" logger should
# also be listed in ClientSharedUtils.initLog4j for removal in case top-level
# file has not been set (e.g. common for JDBC clients) else an empty
# generatedcode.log will be created.

# for generated code of plans
log4j.logger.org.apache.spark.sql.execution.WholeStageCodegenExec=INFO, code
log4j.additivity.org.apache.spark.sql.execution.WholeStageCodegenExec=false
log4j.logger.org.apache.spark.sql.execution.WholeStageCodegenRDD=INFO, code
log4j.additivity.org.apache.spark.sql.execution.WholeStageCodegenRDD=false
# for all Spark generated code (including ad-hoc UnsafeProjection calls etc)
log4j.logger.org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator=DEBUG, code
log4j.additivity.org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator=false
# for SnappyData generated code used on store (ComplexTypeSerializer, JDBC inserts ...)
log4j.logger.org.apache.spark.sql.store.CodeGeneration=DEBUG, code
log4j.additivity.org.apache.spark.sql.store.CodeGeneration=false
