hydra.Prms-testRequirement = "Test to reproduce scenario in SNAP-2228";
hydra.Prms-testDescription = "Test starts snappy and spark clusters. It creates tables and loads data into it.
Later dml operations are executed on the table. While dml operations are done, a the table is
created and dropped and recreated. The dmls should work without any failure irrespective of the
ddl execution. The configuration statements are read from a configuration file. ";

INCLUDE $JTESTS/io/snappydata/hydra/testDMLOps/jdbcClient/jdbcClient.inc;

//task for running dmlOps using JDBC connection
TASK        taskClass   = io.snappydata.hydra.testDMLOps.SnappyDMLOpsUtil taskMethod  = HydraTask_performDMLOp
    threadGroups = snappyStoreThreads;

//task for running dmlOps using smart connector mode
TASK         taskClass   = io.snappydata.hydra.testDMLOps.SnappyDMLOpsUtil taskMethod  = HydraTask_performDMLOpsInApp
    io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.testDMLOps.ValidateDMLOpApp
    io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
    io.snappydata.hydra.cluster.SnappyPrms-hasDynamicAppProps = true
    threadGroups = snappyStoreThreads
    ;

// trigger rebalance
TASK       taskClass  = io.snappydata.hydra.cdcConnector.SnappyCDCTest taskMethod  = HydraTask_performRebalance
           threadGroups = snappyThreads
           maxThreads = 1;


hydra.Prms-totalTaskTimeSec           = 300;
hydra.Prms-maxResultWaitSec           = 900;

io.snappydata.hydra.testDMLOps.SnappySchemaPrms-dmlOperations = ONEOF insert update insert insert delete insert FOENO;

