hydra.Prms-testRequirement = "Test cases for external hive mestore";
hydra.Prms-testDescription = "Create the table in external hive metastore, run the queries on it from Snappy, dropping hive tables from Snappy,
Create Hive schema from Snappy, create Hive table in hive schema from Snappy, load the data to Hive table from Snappy, drop the Hive table and the Hive schema from Snappy,
Create Hive table, insert data to Hive table, alter the Hive table name from Snappy, drop the Hive table from Snappy,
Execute the join queries between the Hive tables and Snappy Tables,
Create External hive table from beeline, access it from snappy, run queries on it from Snappy, drop the table from Snappy.";

INCLUDE $JTESTS/io/snappydata/hydra/northwind/startDualModeCluster.conf;

TASK   taskClass = io.snappydata.hydra.cluster.SnappyTest taskMethod = HydraTask_executeSparkJob
             io.snappydata.hydra.cluster.SnappyPrms-sparkSubmitExtraPrms = " --conf spark.sql.autoBroadcastJoinThreshold=-1"
             io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.hivemetastore.SmartConnectorExternalHiveMetaStore
             io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "${dataFilesLocation}"
             io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
             threadGroups = snappyStoreThreads
             maxTimesToRun = 1;

INCLUDE $JTESTS/io/snappydata/hydra/northwind/stopDualModeCluster.conf;

 // ---> Remove below comments if run on single host with limited resources.
//io.snappydata.hydra.cluster.SnappyPrms-leaderLauncherProps = " -heap-size=1g";
//io.snappydata.hydra.cluster.SnappyPrms-serverLauncherProps = " -heap-size=2g";
io.snappydata.hydra.cluster.SnappyPrms-executorMemory = 5g;
