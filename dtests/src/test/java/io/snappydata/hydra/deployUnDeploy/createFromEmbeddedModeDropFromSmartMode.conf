hydra.Prms-testRequirement = "Test to validate udf creation from embedded mode and deletion from smart connector mode ";
hydra.Prms-testDescription = "The test will create function using udf from embedded mode and then access the created function through
 embedded mode ,jdbc connection and smart connector mode.Then drop the udf from smart connector mode and
 access it in all modes but with expected exception .";

INCLUDE $JTESTS/io/snappydata/hydra/northwind/startDualModeCluster.conf;
//create the user provided udfs in embedded mode.
 INITTASK   taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.hydra.deployUnDeploy.CreateDropUDFSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "udf1=MyUDF3,udf2=MyUDF4,udf3=MyUDF5,isDropUDFFunction=false,jarPath=${jarPath}"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyThreads;


//Access them in embedded mode
 INITTASK   taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.hydra.deployUnDeploy.AccessUdfSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "udf1=MyUDF3,udf2=MyUDF4,udf3=MyUDF5,argNum=25,argStr=snappydata,isException=false"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyThreads;


//Access them through jdbc connection
INITTASK    taskClass = io.snappydata.hydra.deployUnDeploy.SnappyDeployUnDeployTest taskMethod  = HydraTask_executeUDFFunction
            io.snappydata.hydra.deployUnDeploy.SnappyDeployUnDeployPrms-udfName = MyUDF3 MyUDF4 MyUDF5
            io.snappydata.hydra.deployUnDeploy.SnappyDeployUnDeployPrms-isExpectedExecption = false
            threadGroups = leadThreads
            ;

//Access them in smart-connector mode
INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.deployUnDeploy.AccessUdfSparkApp
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "MyUDF3 MyUDF4 MyUDF5 25 snappydata false"
            threadGroups = snappyThreads
            ;

//drop the user provided udfs in smart connector  mode.
 INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
             io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.deployUnDeploy.CreateDropUDFSparkApp
             io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "MyUDF3 MyUDF4 MyUDF5 true ${jarPath}"
             threadGroups = snappyThreads
             ;

//Access the created functions again
//Access them through jdbc connection, this time they should get exception
INITTASK    taskClass = io.snappydata.hydra.deployUnDeploy.SnappyDeployUnDeployTest taskMethod  = HydraTask_executeUDFFunction
            io.snappydata.hydra.deployUnDeploy.SnappyDeployUnDeployPrms-udfName = MyUDF3 MyUDF4 MyUDF5 MyUDF6 MyUDF7
            io.snappydata.hydra.deployUnDeploy.SnappyDeployUnDeployPrms-isExpectedExecption = true
            threadGroups = leadThreads
            ;

//Access them through snappy-job, this time they should get exception
 INITTASK   taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.hydra.deployUnDeploy.AccessUdfSnappyJob
            io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "udf1=MyUDF3,udf2=MyUDF4,udf3=MyUDF5,argNum=25,argStr=snappydata,isException=true"
            io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar
            threadGroups = snappyThreads;

//Access them through smart-connector mode,  this time they should get exception
INITTASK    taskClass   = io.snappydata.hydra.cluster.SnappyTest taskMethod  = HydraTask_executeSparkJob
            io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.hydra.deployUnDeploy.AccessUdfSparkApp
            io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "MyUDF3 MyUDF4 MyUDF5 25 snappydata true"
            threadGroups = snappyThreads
            ;

INCLUDE $JTESTS/io/snappydata/hydra/northwind/stopDualModeCluster.conf;

hydra.Prms-totalTaskTimeSec           = 900;
hydra.Prms-maxResultWaitSec           = 3600;
io.snappydata.hydra.cluster.SnappyPrms-serverMemory = 4g;

io.snappydata.hydra.cluster.SnappyPrms-forceStart = true;
io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-store-scala-tests*tests.jar;