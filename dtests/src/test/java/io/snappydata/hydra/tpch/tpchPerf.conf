//INCLUDE $JTESTS/io/snappydata/hydra/northwind/startDualModeCluster.conf;
INCLUDE $JTESTS/io/snappydata/hydra/tpch/cluster.inc;

INITTASK
  taskClass   = io.snappydata.hydra.cluster.SnappyTest
  taskMethod  = HydraTask_startSnappyCluster
  runMode = always
  threadGroups = snappyThreads
;

// create and load tables using snappyJob
INITTASK
  taskClass   = io.snappydata.hydra.cluster.SnappyTest
  taskMethod  = HydraTask_executeSnappyJob
  io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.benchmark.snappy.tpch.TableCreationJob
  io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "dataLocation=${dataDir},Buckets_Order_Lineitem=${buckets_Order_Lineitem},Buckets_Cust_Part_PartSupp=${buckets_Cust_Part_PartSupp},Buckets_Nation_Region_Supp=${buckets_Nation_Region_Supp},Nation_Region_Supp_col=${Nation_Region_Supp_col},Redundancy=${Redundancy},Persistence=${Persistence},Persistence_Type=${Persistence_Type},NumberOfLoadStages=${NumberOfLoadStages},isParquet=${Parquet}"
  io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-cluster_2.11-0.8-tests.jar
  threadGroups = snappyThreads
;

INITTASK
  taskClass   = io.snappydata.hydra.cluster.SnappyTest
  taskMethod  = HydraTask_executeSnappyJob
  io.snappydata.hydra.cluster.SnappyPrms-jobClassNames = io.snappydata.benchmark.snappy.tpch.QueryExecutionJob
  io.snappydata.hydra.cluster.SnappyPrms-appPropsForJobServer = "queries=${queries},sparkSqlProps=${sparkSqlProperties},isDynamic=${IsDynamic},resultCollection=${ResultCollection},warmUpIterations=${WarmupRuns},actualRuns=${AverageRuns},threadNumber=${threadNumber}"
  io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-cluster_2.11-0.8-tests.jar
  threadGroups = snappyThreads
;

INITTASK
  taskClass   = io.snappydata.hydra.cluster.SnappyTest
  taskMethod  = HydraTask_stopSnappyCluster
  threadGroups = snappyThreads
;

INITTASK
  taskClass   = io.snappydata.hydra.cluster.SnappyTest
  taskMethod  = HydraTask_startSparkCluster
  runMode = always
  threadGroups = workerThreads
;

INITTASK
  taskClass   = io.snappydata.hydra.cluster.SnappyTest
  taskMethod  = HydraTask_executeSparkJob
  io.snappydata.hydra.cluster.SnappyPrms-sparkJobClassNames = io.snappydata.benchmark.snappy.tpch.SparkApp
  io.snappydata.hydra.cluster.SnappyPrms-userAppArgs = "dataLocation=${dataDir},NumberOfLoadStages=${NumberOfLoadStages},isParquet=${Parquet},queries=${queries},sparkSqlProps=${sparkSqlProperties},isDynamic=${IsDynamic},resultCollection=${ResultCollection},warmUpIterations=${WarmupRuns},actualRuns=${AverageRuns},threadNumber=${threadNumber}"
  io.snappydata.hydra.cluster.SnappyPrms-userAppJar = snappydata-cluster_2.11-0.8-tests.jar
  threadGroups = workerThreads
;

CLOSETASK
  taskClass   = io.snappydata.hydra.cluster.SnappyTest
  taskMethod  = HydraTask_stopSparkCluster
  threadGroups = snappyThreads
;

CLOSETASK
  taskClass   = io.snappydata.hydra.cluster.SnappyTest
  taskMethod  = HydraTask_deleteSnappyConfig
  threadGroups = snappyThreads
;

hydra.Prms-totalTaskTimeSec           = 120;
hydra.Prms-maxResultWaitSec           = 1200;
