apply plugin: 'scala'
apply plugin: 'com.github.johnrengelman.shadow'

compileScala.options.encoding = 'UTF-8'

// fix scala+java mix to all use compileScala which uses correct dependency order
sourceSets.main.scala.srcDir "src/main/java"
sourceSets.main.java.srcDirs = []

dependencies {
  compile 'org.scala-lang:scala-library:' + scalaVersion
  compile 'org.scala-lang:scala-reflect:' + scalaVersion
  compile 'org.scala-lang:scala-compiler:' + scalaVersion
  compile(group: 'com.databricks', name: 'spark-csv_2.10', version: '1.2.0') {
    exclude(group: 'org.scala-lang', module: 'scala-library')
    exclude(group: 'org.scala-lang', module: 'scala-reflect')
    exclude(group: 'org.scala-lang', module: 'scala-compiler')
  }
  nospark(group: 'com.databricks', name: 'spark-csv_2.10', version: '1.2.0') {
    exclude(group: 'org.scala-lang', module: 'scala-library')
    exclude(group: 'org.scala-lang', module: 'scala-reflect')
    exclude(group: 'org.scala-lang', module: 'scala-compiler')
  }
  compile project(':snappy-core_' + scalaBinaryVersion)
  if (new File(rootDir, "snappy-spark/build.gradle").exists()) {
    compile project(':snappy-spark:snappy-spark-repl_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-yarn_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-graphx_' + scalaBinaryVersion)
    compile project(':snappy-spark:snappy-spark-hive-thriftserver_' + scalaBinaryVersion)
  } else {
    compile 'io.snappydata:snappy-spark-repl_' + scalaBinaryVersion + ':' + sparkVersion
    compile 'io.snappydata:snappy-spark-yarn_' + scalaBinaryVersion + ':' + sparkVersion
    compile 'io.snappydata:snappy-spark-graphx_' + scalaBinaryVersion + ':' + sparkVersion
    compile 'io.snappydata:snappy-spark-hive-thriftserver_' + scalaBinaryVersion + ':' + sparkVersion
  }
  if (new File(rootDir, "snappy-store/build.gradle").exists()) {
    compile project(':snappy-store:gemfirexd-client')
    compile project(':snappy-store:gemfirexd-core')
    compile project(':snappy-store:gemfirexd-tools')
    nospark project(':snappy-store:gemfirexd-client')
    nospark project(':snappy-store:gemfirexd-core')
    nospark project(':snappy-store:gemfirexd-tools')
    testCompile project(path: ':snappy-store:gemfirexd-tools', configuration: 'testOutput')
  } else {
    compile group: 'io.snappydata', name: 'gemfirexd-client', version: gemfireXDVersion
    compile group: 'io.snappydata', name: 'gemfirexd-core', version: gemfireXDVersion
    compile group: 'io.snappydata', name: 'gemfirexd-tools', version: gemfireXDVersion
    nospark group: 'io.snappydata', name: 'gemfirexd-client', version: gemfireXDVersion
    nospark group: 'io.snappydata', name: 'gemfirexd-core', version: gemfireXDVersion
    nospark group: 'io.snappydata', name: 'gemfirexd-tools', version: gemfireXDVersion
    testCompile group: 'io.snappydata', name: 'gemfirexd-tools', version: gemfireXDVersion, classifier: 'tests'
  }

  if (new File(rootDir, "spark-jobserver/build.gradle").exists()) {
    compile project(':spark-jobserver')
  } else {
    compile group: 'io.snappydata', name: 'spark-jobserver', version: '0.6.0'
  }
  nospark 'org.apache.tomcat:tomcat-jdbc:8.0.32'
  nospark 'com.zaxxer:HikariCP:2.4.4'

  testCompile project(path: ':snappy-core_' + scalaBinaryVersion, configuration: 'testOutput')
  testCompile 'org.scalatest:scalatest_' + scalaBinaryVersion + ':2.2.1'

  testRuntime 'org.pegdown:pegdown:1.1.0'
}

task packageScalaDocs(type: Jar, dependsOn: scaladoc) {
  classifier = 'javadoc'
  from scaladoc
}
if (rootProject.hasProperty('enablePublish')) {
  artifacts {
    archives packageScalaDocs, packageSources
  }
}

testClasses.doLast {
  copyTestsCommonResources(buildDir)
}

task deleteDocsDir(type: Delete) {
  delete "${rootProject.buildDir}/docs"
}

task docs(type: ScalaDoc) {
  dependsOn ':snappy-tools_' + scalaBinaryVersion + ':deleteDocsDir'
  Set<String> allSource = []
  def docProjects = rootProject.subprojects.collectMany { project ->
    if ((project.plugins.hasPlugin('scala') || project.plugins.hasPlugin('java')) &&
        // jobserver depends on Apache Spark 1.5.x which causes conflicts
        !project.path.contains('snappy-store') &&
        !project.name.contains('jobserver') &&
        // below three will get filtered with the snappy-store path check itself
        // but still keeping it as when we would remove the snappy-store path filter
        // still the below three sub prejects should not be built.
        !project.name.contains('jgroups') &&
        !project.name.contains('gemfire-examples') &&
        !project.name.contains('trove') &&
        // exclude tests
        !project.name.contains('tests') && !project.name.contains('dunits')) {
      allSource.addAll(project.sourceSets.main.allJava.findAll {
        !it.getPath().matches('.*/internal/.*') && !it.getPath().contains('com/gemstone/gemfire/cache/operations/')
      })
      if (project.plugins.hasPlugin('scala')) {
        allSource.addAll(project.sourceSets.main.allScala)
      }
      [ project ]
    } else []
  }
  source = allSource
  classpath = files(docProjects.collect { project ->
    // println("Got project = $project")
    project.sourceSets.main.compileClasspath
  })
  destinationDir = file("${rootProject.buildDir}/docs")
}

def copyDirs(def srcDir, def destDir) {
  mkdir(destDir)
  copy {
    from srcDir
    into destDir
  }
}

test.dependsOn ':cleanJUnit'
scalaTest {
  // This property is a temporary fix for scala tests to not use default-persistent
  // connection property in SnappyHiveCatalog
  systemProperty "scalaTest", "true"
  dependsOn ':cleanScalaTest'
  doFirst {
    // cleanup files since scalatest plugin does not honour workingDir yet
    cleanIntermediateFiles(project.path)
  }
  doLast {
    // cleanup files since scalatest plugin does not honour workingDir yet
    cleanIntermediateFiles(project.path)
  }
}
check.dependsOn ':product', test, scalaTest

shadowJar {
  zip64 = true

  //inputs.files jar.outputs.files
  //outputs.file "${buildDir}/libs/${archiveName}"

  mergeServiceFiles {
    exclude 'META-INF/*.SF'
    exclude 'META-INF/*.DSA'
    exclude 'META-INF/*.RSA'
  }
  append('META-INF/services/org.apache.hadoop.fs.FileSystem')
  append('reference.conf')
  exclude 'org/datanucleus/**'
  exclude 'log4j.properties'

  if (rootProject.hasProperty('enablePublish')) {
    createdBy = "SnappyData Build Team"
  } else {
    createdBy = System.getProperty("user.name")
  }
  manifest {
    attributes(
      "Manifest-Version"  : "1.0",
      "Created-By"        : createdBy,
      "Title"             : rootProject.name,
      "Version"           : version,
      "Vendor"            : "SnappyData, Inc."
    )
  }
}

task nosparkJar(type: com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar) {
  dependsOn project(':snappy-core_' + scalaBinaryVersion).jar, jar
  zip64 = true
  baseName = 'snappydata'
  classifier = ''

  from {
    project.configurations.nospark +
    project(':snappy-core_' + scalaBinaryVersion).jar.outputs.files +
    jar.outputs.files
  }
  mergeServiceFiles {
    exclude 'META-INF/*.SF'
    exclude 'META-INF/*.DSA'
    exclude 'META-INF/*.RSA'
  }
  exclude 'jobserver*.conf'
  exclude 'log4j.properties'

  if (rootProject.hasProperty('enablePublish')) {
    createdBy = "SnappyData Build Team"
  } else {
    createdBy = System.getProperty("user.name")
  }
  manifest {
    attributes(
      "Manifest-Version"  : "1.0",
      "Created-By"        : createdBy,
      "Title"             : rootProject.name,
      "Version"           : version,
      "Vendor"            : "SnappyData, Inc."
    )
  }
}
shadowJar.dependsOn nosparkJar
